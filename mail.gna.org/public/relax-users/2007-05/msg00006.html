<!-- MHonArc v2.6.16 -->
<!--X-Subject: Re: full&#45;analysis.py -->
<!--X-From-R13: Vbatlna Zv <ulyvpurzNuxhpp.uxh.ux> -->
<!--X-Date: Tue, 08 May 2007 06:51:22 +0200 -->
<!--X-Message-Id: 1178599800.46400178bd375@imp4.webmail.hku.hk -->
<!--X-Content-Type: multipart/mixed -->
<!--X-Reference: 1178271136.463afda0d508e@imp4.webmail.hku.hk -->
<!--X-Reference: 7f080ed10705071611m4c7ca40fk58250a8201c0e6fd@mail.gmail.com -->
<!--X-Head-End-->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>Re: full-analysis.py -- May 08, 2007 - 06:51</title>
<link rel="stylesheet" type="text/css" href="/mail.gna.org/archives-color-gna.css"> 
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>
<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->
<h2><img src="/mail.gna.org/images/mail.orig.png" width="48" height="48"
alt="mail" class="pageicon" />Re: full-analysis.py</h2>
<br />
<div class="topmenu">
<a href="../" class="tabs">Others Months</a> | <a href="index.html#00006" class="tabs">Index by Date</a> | <a href="threads.html#00006" class="tabs">Thread Index</a><br />
<span class="smaller">&gt;&gt;&nbsp;&nbsp;
[<a href="msg00005.html">Date Prev</a>] [<a href="msg00007.html">Date Next</a>] [<a href="msg00005.html">Thread Prev</a>] [<a href="msg00007.html">Thread Next</a>]
</div>

<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->
<h3><a name="header" href="#header">Header</a></h3>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->
<ul class="headdata">
<li class="menuitem">
<em>To</em>: &quot;Edward d'Auvergne&quot; &lt;edward.dauvergne@xxxxxxxxx&gt;</li>
<li class="menuitem">
<em>Date</em>: Tue,  8 May 2007 12:50:00 +0800</li>
<li class="menuitem">
<em>Cc</em>: relax-users@xxxxxxx</li>
<li class="menuitem">
<em>Message-id</em>: &lt;<a href="msg00006.html">1178599800.46400178bd375@imp4.webmail.hku.hk</a>&gt;</li>
<li class="menuitem">
<em>References</em>: &lt;1178271136.463afda0d508e@xxxxxxxxxxxxxxxxxxx&gt;	&lt;7f080ed10705071611m4c7ca40fk58250a8201c0e6fd@xxxxxxxxxxxxxx&gt;</li>
<li class="menuitem">
<em>User-agent</em>: Internet Messaging Program (IMP) 3.2.2</li>
</ul>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
</div><!-- end headdata -->
<br />
<h3><a name="content" href="#content">Content</a></h3>
<div class="postedby">Posted by <strong>Hongyan Li</strong> on May 08, 2007 - 06:51:</div>
<div class="msgdata">
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<pre style="margin: 0em;">Dear  Edward,
I have set sel.diff_model=local_tm, sphere, prolate, oblate and ellipsoid and
run full_analysis.py each time to generate directory and init in each model 
and
then set sel.diff_model=final to run the script again. RelaxError: No 
diffusion
tensor data is loaded for the run 'final' appears and please see the attached
file for the information appeared on the screen.
Best regards,
Hongyan

Quoting Edward d'Auvergne &lt;edward.dauvergne@xxxxxxxxx&gt;:

</pre><blockquote class="blockquote"><pre style="margin: 0em;">Hi,

Unfortunately I cannot determine what the problem is with this
information.  Would you be able to include a few more details
including what you had run prior to this error occurring.  Maybe a
number of lines printed from relax would help as well.  Also if you
run relax with the '--debug' command line argument, more information
about the error will be printed and hopefully a save file which can be
attached to a bug report (<a  rel="nofollow" href="https://web.archive.org/web/https://gna.org/bugs/?group=relax">https://gna.org/bugs/?group=relax</a>) along
with the script.  Any additional information would be appreciated.
Even a recursive file and directory listing could be useful in pinning
down the problem.

Cheers,

Edward



On 5/4/07, Hongyan Li &lt;hylichem@xxxxxxxxxxxx&gt; wrote:
</pre><blockquote class="blockquote"><pre style="margin: 0em;">Dear relax users,
when I run full-analysis.py script, I got the error message (no diffusion
</pre></blockquote><pre style="margin: 0em;">tensor
</pre><blockquote class="blockquote"><pre style="margin: 0em;">data is loaded for the run 'tensor'). I am not sure how to set tensor, 
does
</pre></blockquote><pre style="margin: 0em;">the
</pre><blockquote class="blockquote"><pre style="margin: 0em;">program automatically generate tensor from pdb files?

Any suggestion will be highly appreciated!

best regards,
Hongyan

Dr. Hongyan Li
Department of Chemistry
The University of Hong Kong
Pokfulam Road
Hong Kong


_______________________________________________
relax (<a  rel="nofollow" href="http://nmr-relax.com">http://nmr-relax.com</a>)

This is the relax-users mailing list
relax-users@xxxxxxx

To unsubscribe from this list, get a password
reminder, or change your subscription options,
visit the list information page at
<a  rel="nofollow" href="http://www.nmr-relax.com/mail.gna.org/listinfo/relax-users">https://mail.gna.org/listinfo/relax-users</a>

</pre></blockquote><pre style="margin: 0em;">

</pre></blockquote><pre style="margin: 0em;">


Dr. Hongyan Li
Department of Chemistry
The University of Hong Kong
Pokfulam Road
Hong Kong
</pre><pre style="margin: 0em;">Script started on Tue 08 May 2007 12:36:05 PM HKT
[1mhsun@com371:~/SAMCx-CN/relax-1.2.9/full_analysis&gt;[mrelax 
full_analysis.py 




                                            relax 1.2.9

                          Protein dynamics by NMR relaxation data analysis

                             Copyright (C) 2001-2006 Edward d'Auvergne

This is free software which you are welcome to modify and redistribute under 
the conditions of the
GNU General Public License (GPL).  This program, including all modules, is 
licensed under the GPL
and comes with absolutely no warranty.  For details type 'GPL'.  Assistance 
in using this program
can be accessed by typing 'help'.

script = 'full_analysis.py'
----------------------------------------------------------------------------------------------------
# Script for complete model-free analysis.
#
# This script is designed for those who appreciate black-boxes, although it 
will need to be
# heavily tailored to the protein in question, or those who appreciate 
complex code.  For a
# description of object-oriented coding in python using classes, 
functions/methods, self, etc,
# see the python tutorial.


# Import functions from the python modules 'os' and 're'.
from os import getcwd, listdir
from re import search


class Main:
    def __init__(self):
        &quot;&quot;&quot;Script for black-box model-free analysis.

        The value of the variable self.diff_model will determine the 
behaviour of this script.  The
        five diffusion models used in this script are:

            Model I   (MI)   - Local tm.
            Model II  (MII)  - Sphere.
            Model III (MIII) - Prolate spheroid.
            Model IV  (MIV)  - Oblate spheroid.
            Model V   (MV)   - Ellipsoid.

        Model I must be optimised prior to any of the other diffusion models, 
while the Models II to
        V can be optimised in any order.  To select the various models, set 
the variable
        self.diff_model to the following strings:

            MI   - 'local_tm'
            MII  - 'sphere'
            MIII - 'prolate'
            MIV  - 'oblate'
            MV   - 'ellipsoid'

        This approach has the advantage of eliminating the need for an 
initial estimate of a global
        diffusion tensor and removing all the problems associated with the 
initial estimate.

        It is important that the number of parameters in a model does not 
excede the number of
        relaxation data sets for that residue.  If this is the case, the list 
of models in the
        'multi_model' functions will need to be trimmed.


        Model I - Local tm
        ~~~~~~~~~~~~~~~~~~

        This will optimise the diffusion model whereby all residues of the 
protein have a local tm
        value, i.e. there is no global diffusion tensor.  This model needs to 
be optimised prior to
        optimising any of the other diffusion models.  Each residue is fitted 
to the multiple model-
        free models separately, where the parameter tm is included in each 
model.

        AIC model selection is used to select the models for each residue.


        Model II - Sphere
        ~~~~~~~~~~~~~~~~~

        This will optimise the isotropic diffusion model.  Multiple steps are 
required, an initial
        optimisation of the diffusion tensor, followed by a repetitive 
optimisation until
        convergence of the diffusion tensor.  Each of these steps requires 
this script to be rerun.
        For the initial optimisation, which will be placed in the directory 
'./sphere/init/', the
        following steps are used:

        The model-free models and parameter values for each residue are set 
to those of diffusion
        model MI.

        The local tm parameter is removed from the models.

        The model-free parameters are fixed and a global spherical diffusion 
tensor is minimised.


        For the repetitive optimisation, each minimisation is named from 
'round_1' onwards.  The
        initial 'round_1' optimisation will extract the diffusion tensor from 
the results file in
        './sphere/init/', and the results will be placed in the directory 
'./sphere/round_1/'.  Each
        successive round will take the diffusion tensor from the previous 
round.  The following
        steps are used:

        The global diffusion tensor is fixed and the multiple model-free 
models are fitted to each
        residue.

        AIC model selection is used to select the models for each residue.

        All model-free and diffusion parameters are allowed to vary and a 
global optimisation of all
        parameters is carried out.


        Model III - Prolate spheroid
        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        The methods used are identical to those of diffusion model MII, 
except that an axially
        symmetric diffusion tensor with Da &gt;= 0 is used.  The base directory 
containing all the
        results is './prolate/'.


        Model IV - Oblate spheroid
        ~~~~~~~~~~~~~~~~~~~~~~~~~~

        The methods used are identical to those of diffusion model MII, 
except that an axially
        symmetric diffusion tensor with Da &lt;= 0 is used.  The base directory 
containing all the
        results is './oblate/'.


        Model V - Ellipsoid
        ~~~~~~~~~~~~~~~~~~~

        The methods used are identical to those of diffusion model MII, 
except that a fully
        anisotropic diffusion tensor is used (also known as rhombic or 
asymmetric diffusion).  The
        base directory is './ellipsoid/'.



        Final run
        ~~~~~~~~~

        Once all the diffusion models have converged, the final run can be 
executed.  This is done
        by setting the variable self.diff_model to 'final'.  This consists of 
two steps, diffusion
        tensor model selection, and Monte Carlo simulations.  Firstly AIC 
model selection is used to
        select between the diffusion tensor models.  Monte Carlo simulations 
are then run soley on
        this selected diffusion model.  Minimisation of the model is bypassed 
as it is assumed that
        the model is already fully optimised (if this is not the case the 
final run is not yet
        appropriate).

        The final black-box model-free results will be placed in the file 
'final/results'.
        &quot;&quot;&quot;

        # The diffusion model (this is the variable which should be changed).
        self.diff_model = 'final'


        # MI - Local tm.
        ################

        if self.diff_model == 'local_tm':
            # Base directory to place files into.
            self.base_dir = 'local_tm/'

            # Sequential optimisation of all model-free models (function must 
be modified to suit).
            self.multi_model(local_tm=1)

            # Model selection run.
            run.create('aic', 'mf')

            # Model selection.
            self.model_selection(run='aic', dir=self.base_dir + 'aic')


        # Diffusion models MII to MV.
        #############################

        elif self.diff_model == 'sphere' or self.diff_model == 'prolate' or 
self.diff_model == 'oblate' or self.diff_model == 'ellipsoid':
            # Determine which round of optimisation to do (init, round_1, 
round_2, etc).
            self.round = self.determine_rnd(model=self.diff_model)


            # Inital round of optimisation for diffusion models MII to MV.
            if self.round == 0:
                # Base directory to place files into.
                self.base_dir = self.diff_model + '/init/'

                # Run name.
                name = self.diff_model

                # Create the run.
                run.create(name, 'mf')

                # Load the local tm diffusion model MI results.
                results.read(run=name, file='results', dir='local_tm/aic')

                # Remove the tm parameter.
                model_free.remove_tm(run=name)

                # Load the PDB file.
                pdb(name, 'sam-rdc.pdb')

                # Add an arbitrary diffusion tensor which will be optimised.
                if self.diff_model == 'sphere':
                    diffusion_tensor.init(name, 10e-9, fixed=0)
                    inc = 11
                elif self.diff_model == 'prolate':
                    diffusion_tensor.init(name, (10e-9, 0, 0, 0), 
spheroid_type='prolate', fixed=0)
                    inc = 11
                elif self.diff_model == 'oblate':
                    diffusion_tensor.init(name, (10e-9, 0, 0, 0), 
spheroid_type='oblate', fixed=0)
                    inc = 11
                elif self.diff_model == 'ellipsoid':
                    diffusion_tensor.init(name, (10e-09, 0, 0, 0, 0, 0), 
fixed=0)
                    inc = 6

                # Minimise just the diffusion tensor.
                fix(name, 'all_res')
                grid_search(name, inc=inc)
                minimise('newton', run=name)

                # Write the results.
                results.write(run=name, file='results', dir=self.base_dir, 
force=1)


            # Normal round of optimisation for diffusion models MII to MV.
            else:
                # Base directory to place files into.
                self.base_dir = self.diff_model + '/round_' + `self.round` + 
'/'

                # Load the optimised diffusion tensor from either the 
previous round.
                self.load_tensor()

                # Sequential optimisation of all model-free models (function 
must be modified to suit).
                self.multi_model()

                # Delete the run containing the optimised diffusion tensor.
                run.delete('tensor')

                # Create the final run (for model selection and final 
optimisation).
                name = 'final'
                run.create(name, 'mf')

                # Model selection.
                self.model_selection(run=name, dir=self.base_dir + 'aic')

                # Final optimisation of all diffusion and model-free 
parameters.
                fix(name, 'all', fixed=0)

                # Minimise all parameters.
                minimise('newton', run=name)

                # Write the results.
                dir = self.base_dir + 'opt'
                results.write(run=name, file='results', dir=dir, force=1)


        # Final run.
        ############

        elif self.diff_model == 'final':
            # Diffusion model selection.
            ############################

            # Create the local_tm run.
            run.create('local_tm', 'mf')

            # Load the local tm diffusion model MI results.
            results.read(run='local_tm', file='results', dir='local_tm/aic')

            # Loop over models MII to MV.
            for model in ['sphere', 'prolate', 'oblate', 'ellipsoid']:
                # Determine which was the last round of optimisation for each 
of the models.
                self.round = self.determine_rnd(model=model) - 1

                # Skip the diffusion model if no directories begining with 
'round_' exist.
                if self.round &lt; 1:
                    continue

                # Create the run.
                run.create(model, 'mf')

                # Load the diffusion model results.
                results.read(run=model, file='results', dir=model + '/round_' 
+ `self.round` + '/opt')

            # Create the run for model selection (which will be a copy of the 
selected diffusion model or run).
            run.create('final', 'mf')

            # Model selection between MI to MV.
            self.model_selection(run='final', write_flag=0)


            # Monte Carlo simulations.
            ##########################

            # Fix the diffusion tensor.
            fix('final', 'diff')

            # Simulations.
            monte_carlo.setup('final', number=200)
            monte_carlo.create_data('final')
            monte_carlo.initial_values('final')
            minimise('newton', run='final')
            eliminate('final')
            monte_carlo.error_analysis('final')


            # Write the final results.
            ##########################

            results.write(run='final', file='results', dir='final', force=1)


        # Unknown script behaviour.
        ###########################

        else:
            raise RelaxError, &quot;Unknown diffusion model, change the value of 
'self.diff_model'&quot;


    def determine_rnd(self, model=None):
        &quot;&quot;&quot;Function for returning the name of next round of optimisation.&quot;&quot;&quot;

        # Get a list of all files in the directory model.  If no directory 
exists, set the round to 'init' or 0.
        try:
            dir_list = listdir(getcwd() + '/' + model)
        except:
            return 0

        # Set the round to 'init' or 0 if there is no directory called 'init'.
        if 'init' not in dir_list:
            return 0

        # Create a list of all files which begin with 'round_'.
        rnd_dirs = []
        for file in dir_list:
            if search('^round_', file):
                rnd_dirs.append(file)

        # Create a sorted list of integer round numbers.
        numbers = []
        for dir in rnd_dirs:
            try:
                numbers.append(int(dir[6:]))
            except:
                pass
        numbers.sort()

        # No directories begining with 'round_' exist, set the round to 1.
        if not len(numbers):
            return 1

        # Determine the number for the next round (add 1 to the highest 
number).
        return numbers[-1] + 1


    def load_tensor(self):
        &quot;&quot;&quot;Function for loading the optimised diffusion tensor.&quot;&quot;&quot;

        # Create the run for the previous data.
        run.create('tensor', 'mf')

        # Load the optimised diffusion tensor from the initial round.
        if self.round == 1:
            results.read('tensor', 'results', self.diff_model + '/init')

        # Load the optimised diffusion tensor from the previous round.
        else:
            results.read('tensor', 'results', self.diff_model + '/round_' + 
`self.round - 1` + '/opt')


    def model_selection(self, run=None, dir=None, write_flag=1):
        &quot;&quot;&quot;Model selection function.&quot;&quot;&quot;

        # Model elimination.
        eliminate()

        # Model selection.
        model_selection('AIC', run)

        # Write the results.
        if write_flag:
            results.write(run=run, file='results', dir=dir, force=1)


    def multi_model(self, local_tm=0):
        &quot;&quot;&quot;Function for optimisation of all model-free models.&quot;&quot;&quot;

        # Set the run names (also the names of preset model-free models).
        if local_tm:
            runs = ['tm0', 'tm1', 'tm2', 'tm3', 'tm4', 'tm5', 'tm6', 'tm7', 
'tm8', 'tm9']
        else:
            runs = ['m0', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 
'm9']

        # Nuclei type
        nuclei('N')

        for name in runs:
            # Create the run.
            run.create(name, 'mf')

            # Load the sequence.
            sequence.read(name, 'noe.600.out')

            # Load the PDB file.
            if not local_tm:
                pdb(name, 'sam-rdc.pdb')

            # Load the relaxation data.
            relax_data.read(name, 'R1', '600', 600.13 * 1e6, 'r1.600.out')
            relax_data.read(name, 'R2', '600', 600.13 * 1e6, 'r2.600.out')
            relax_data.read(name, 'NOE', '600', 600.13 * 1e6, 'noe.600.out')
            
            # Unselect unresolved residues.
            #unselect.read(name, file='unresolved')

            # Copy the diffusion tensor from the run 'opt' and prevent it 
from being minimised.
            if not local_tm:
                diffusion_tensor.copy('tensor', name)
                fix(name, 'diff')

            # Set the bond length and CSA values.
            value.set(name, 1.02 * 1e-10, 'bond_length')
            value.set(name, -172 * 1e-6, 'csa')

            # Select the model-free model.
            model_free.select_model(run=name, model=name)

            # Minimise.
            grid_search(name, inc=11)
            minimise('newton', run=name)

            # Write the results.
            dir = self.base_dir + name
            results.write(run=name, file='results', dir=dir, force=1)


# The main class.
Main()
----------------------------------------------------------------------------------------------------

relax&gt; run.create(run='local_tm', run_type='mf')

relax&gt; results.read(run='local_tm', file='results', dir='local_tm/aic', 
format='columnar')
Opening the file 'local_tm/aic/results.bz2' for reading.

relax&gt; run.create(run='final', run_type='mf')

relax&gt; eliminate(run=None, function=None, args=None)

relax&gt; model_selection(method='AIC', modsel_run='final', runs=None)
AIC model selection.

Instance 0.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 1.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 2.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 3.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 4.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 5.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.77288        
      4.77288             

The model from the run 'local_tm' has been selected.

Instance 6.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             1                    3                    1.41399        
      3.41399             

The model from the run 'local_tm' has been selected.

Instance 7.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 8.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 9.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    1.15000        
      5.15000             

The model from the run 'local_tm' has been selected.

Instance 10.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.12856        
      4.12856             

The model from the run 'local_tm' has been selected.

Instance 11.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.50239        
      4.50239             

The model from the run 'local_tm' has been selected.

Instance 12.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.00226        
      4.00226             

The model from the run 'local_tm' has been selected.

Instance 13.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.30244        
      4.30244             

The model from the run 'local_tm' has been selected.

Instance 14.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    1.95113        
      5.95113             

The model from the run 'local_tm' has been selected.

Instance 15.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.18734        
      4.18734             

The model from the run 'local_tm' has been selected.

Instance 16.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.30022        
      4.30022             

The model from the run 'local_tm' has been selected.

Instance 17.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.19671        
      4.19671             

The model from the run 'local_tm' has been selected.

Instance 18.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 19.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.00919        
      4.00919             

The model from the run 'local_tm' has been selected.

Instance 20.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    1.32035        
      5.32035             

The model from the run 'local_tm' has been selected.

Instance 21.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 22.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.95633        
      4.95633             

The model from the run 'local_tm' has been selected.

Instance 23.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.10473        
      4.10473             

The model from the run 'local_tm' has been selected.

Instance 24.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.11792        
      4.11792             

The model from the run 'local_tm' has been selected.

Instance 25.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    1.58317        
      5.58317             

The model from the run 'local_tm' has been selected.

Instance 26.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.05478        
      4.05478             

The model from the run 'local_tm' has been selected.

Instance 27.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.00029        
      4.00029             

The model from the run 'local_tm' has been selected.

Instance 28.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.28605        
      4.28605             

The model from the run 'local_tm' has been selected.

Instance 29.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.31213        
      4.31213             

The model from the run 'local_tm' has been selected.

Instance 30.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 31.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.01781        
      4.01781             

The model from the run 'local_tm' has been selected.

Instance 32.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.92658        
      4.92658             

The model from the run 'local_tm' has been selected.

Instance 33.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    1.39575        
      5.39575             

The model from the run 'local_tm' has been selected.

Instance 34.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.00102        
      4.00102             

The model from the run 'local_tm' has been selected.

Instance 35.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             1                    3                    2.48640        
      4.48640             

The model from the run 'local_tm' has been selected.

Instance 36.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             1                    3                    1.63000        
      3.63000             

The model from the run 'local_tm' has been selected.

Instance 37.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.41412        
      4.41412             

The model from the run 'local_tm' has been selected.

Instance 38.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    1.81545        
      5.81545             

The model from the run 'local_tm' has been selected.

Instance 39.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 40.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             1                    3                    3.77726        
      5.77726             

The model from the run 'local_tm' has been selected.

Instance 41.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 42.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 43.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 44.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 45.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 46.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 47.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 48.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 49.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 50.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 51.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 52.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 53.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             3                    3                    0.00000        
      6.00000             

The model from the run 'local_tm' has been selected.

Instance 54.

Run                  Num_params_(k)       Num_data_sets_(n)    Chi2           
      Criterion           
local_tm             2                    3                    0.44453        
      4.44453             

The model from the run 'local_tm' has been sele

relax&gt; fix(run='final', element='diff', fixed=1)
RelaxError: No diffusion tensor data is loaded for the run 'final'.

</pre>
<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
</div><!-- end msgdata -->
<br />
<h3><a name="related" href="#related">Related Messages</a></h3>
<div class="relateddata">
<ul><li><strong>Follow-Ups</strong>:
<ul>
<li><strong><a name="00007" href="msg00007.html">Re: full-analysis.py</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
</ul></li></ul>
<!--X-Follow-Ups-End-->
<!--X-References-->
<ul><li><strong>References</strong>:
<ul>
<li><strong><a name="00000" href="msg00000.html">full-analysis.py</a></strong>
<ul><li><em>From:</em> Hongyan Li</li></ul></li>
<li><strong><a name="00005" href="msg00005.html">Re: full-analysis.py</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
</ul></li></ul>
<!--X-References-End-->
<!--X-BotPNI-->
</div><!-- end relateddata -->
<!-- NoBotLinksApartFromRelatedMessages -->

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->
<div class="footer"></div><br />
<div class="right">Powered by <a href="http://www.mhonarc.org">MHonArc</a>, Updated Tue May 08 09:40:17 2007</div>  
</body>
</html>
