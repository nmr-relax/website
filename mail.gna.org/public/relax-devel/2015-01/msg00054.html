<!-- MHonArc v2.6.18 -->
<!--X-Subject: Re: [task #7882] Implement Monte&#45;Carlo simulation, where errors are generated with width of standard deviation or residuals -->
<!--X-From-R13: Febryf Szgrxæe Zvaarg &#60;gyvaargNaze&#45;erynk.pbz> -->
<!--X-Date: Mon, 19 Jan 2015 10:54:39 +0100 -->
<!--X-Message-Id: CA+CBx2MEnCdcB_bD8jMV6_24&#45;+59gLt21=xLso1jv7qDX2h9Vg@mail.gmail.com -->
<!--X-Content-Type: text/plain -->
<!--X-Reference: 20150116&#45;161430.sv20529.18990@gna.org -->
<!--X-Reference: CAED9pY9Ptz7oi+jFAENz=kk9+62Cy+BSjQ+_YHpk6ou5iivqkw@mail.gmail.com -->
<!--X-Reference: CA+CBx2PXMLmqGVVfKZWwV_OR2Qx0QPVebaYnoebZ4W&#45;t3fj6CA@mail.gmail.com -->
<!--X-Reference: CAED9pY9xFdgK=y==pHoEbd5=0v1qXd&#45;SXdM+czNo0vE2Fx7FQg@mail.gmail.com -->
<!--X-Reference: CA+CBx2P_mhA1hcB01ACYcyqAZwFakMD6BLwJ3q8jdWBwQYJ_ZA@mail.gmail.com -->
<!--X-Reference: CAED9pY9fn7ONn+MeknhH5Hm_bPrZwjfvkngZUwMc6SxTB4HNEg@mail.gmail.com -->
<!--X-Reference: CAED9pY&#45;qXRehqq&#45;=SJ2K&#45;cU1PkmF9GmhNi4uXGz8h4xr+JZZUw@mail.gmail.com -->
<!--X-Reference: CAED9pY8Ou+HaBez3YdXeA=3by6A_a3QJH2qPVqk3nsCGKEOM2Q@mail.gmail.com -->
<!--X-Head-End-->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>Re: [task #7882] Implement Monte-Carlo simulation, where errors are generated with width of standard deviation or residuals -- January 19, 2015 - 10:54</title>
<link rel="stylesheet" type="text/css" href="/mail.gna.org/archives-color-gna.css"> 
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>
<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->
<h2><img src="/mail.gna.org/images/mail.orig.png" width="48" height="48"
alt="mail" class="pageicon" />Re: [task #7882] Implement Monte-Carlo simulation, where errors are generated with width of standard deviation or residuals</h2>
<br />
<div class="topmenu">
<a href="../" class="tabs">Others Months</a> | <a href="index.html#00054" class="tabs">Index by Date</a> | <a href="threads.html#00054" class="tabs">Thread Index</a><br />
<span class="smaller">&gt;&gt;&nbsp;&nbsp;
[<a href="msg00053.html">Date Prev</a>] [<a href="msg00055.html">Date Next</a>] [<a href="msg00049.html">Thread Prev</a>] [<a href="msg00058.html">Thread Next</a>]
</div>

<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->
<h3><a name="header" href="#header">Header</a></h3>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->
<ul class="headdata">
<li class="menuitem">
<em>To</em>: &quot;Edward d'Auvergne&quot; &lt;edward@xxxxxxxxxxxxx&gt;</li>
<li class="menuitem">
<em>Date</em>: Mon, 19 Jan 2015 10:53:48 +0100</li>
<li class="menuitem">
<em>Cc</em>: &quot;Troels E. Linnet&quot; &lt;NO-REPLY.INVALID-ADDRESS@xxxxxxx&gt;, &quot;relax-devel@xxxxxxx&quot; &lt;relax-devel@xxxxxxx&gt;</li>
<li class="menuitem">
<em>Dkim-signature</em>: v=1; a=rsa-sha256; c=relaxed/relaxed; d=gmail.com; s=20120113; h=mime-version:sender:in-reply-to:references:from:date:message-id :subject:to:cc:content-type; bh=Eeda9l9tLXeZDMHpfK3mCkt9kmmSc9sRvDG1Pdbd7rM=; b=BjY0wVE5nMtaZ4fWmTddajvKx0sDezAQLJEGEvnAQ56DxqrLSPZwfux+PBgYFU2Zz9 yYu6VEsjTxIVEfwhPd75eV0aD1IGCO2qHSvGZykdAJ5OXR7Y5HcAIUOVR9RdLHZ88A1q r4jRDEH2nYJ9AKdBizm/ohVVNjOV4ZuQ7chfKWmSszD9Ha17BrYR+8m6pUiQ9O7WP6Xe 2wLzFXTGWPBr4MJVh6NmtFeBhxYG3J5zJWJNhkdn4p7IBsTG4bSmHzPPO5XlhbSnrJay I9FN2eUmKeeV308eq9do5XgwZk79J9c1J3IlQRG6VEa6NEQeoQUh21uM0d3RGTifka7f gRzw==</li>
<li class="menuitem">
<em>Message-id</em>: &lt;CA+CBx2MEnCdcB_bD8jMV6_24-+59gLt21=xLso1jv7qDX2h9Vg@mail.gmail.com&gt;</li>
<li class="menuitem">
<em>References</em>: &lt;<a href="msg00034.html">20150116-161430.sv20529.18990@gna.org</a>&gt; &lt;CAED9pY9Ptz7oi+jFAENz=kk9+62Cy+BSjQ+_YHpk6ou5iivqkw@mail.gmail.com&gt; &lt;<a href="msg00036.html">CA+CBx2PXMLmqGVVfKZWwV_OR2Qx0QPVebaYnoebZ4W-t3fj6CA@mail.gmail.com</a>&gt; &lt;CAED9pY9xFdgK=y==pHoEbd5=0v1qXd-SXdM+czNo0vE2Fx7FQg@mail.gmail.com&gt; &lt;<a href="msg00038.html">CA+CBx2P_mhA1hcB01ACYcyqAZwFakMD6BLwJ3q8jdWBwQYJ_ZA@mail.gmail.com</a>&gt; &lt;<a href="msg00039.html">CAED9pY9fn7ONn+MeknhH5Hm_bPrZwjfvkngZUwMc6SxTB4HNEg@mail.gmail.com</a>&gt; &lt;CAED9pY-qXRehqq-=SJ2K-cU1PkmF9GmhNi4uXGz8h4xr+JZZUw@mail.gmail.com&gt; &lt;CAED9pY8Ou+HaBez3YdXeA=3by6A_a3QJH2qPVqk3nsCGKEOM2Q@mail.gmail.com&gt;</li>
</ul>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
</div><!-- end headdata -->
<br />
<h3><a name="content" href="#content">Content</a></h3>
<div class="postedby">Posted by <strong>Troels Emtekær Linnet</strong> on January 19, 2015 - 10:54:</div>
<div class="msgdata">
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<pre style="margin: 0em;">Hi Edward.

I have used this regression book.
<a  rel="nofollow" href="http://www.graphpad.com/faq/file/Prism4RegressionBook.pdf">http://www.graphpad.com/faq/file/Prism4RegressionBook.pdf</a>

I like the language (fun and humoristic), and goes over a great detail.
For example, there is quite a list of weighting methods.
I find the comments on page 28 a little disturbing.
(See also page 86+87)

The Monte-Carlo simulation is described at page 104.

1) Create an ideal data set.
-&gt; Check. This is done with relax
monte_carlo.create_data(method='back_calc')

2) Add random scatter.
relax now add random scatter, per individual datapoint. The random scatter
is drawn from the measured error of the datapoint.
But the book suggest adding errors described by variance of the residuals.
This is described at page 33.
&quot;If you chose to weight the values and minimize the relative distance
squared (or some other weighting function), goodness-of-fit is quantified
with the weighted sum- of-squares.&quot;

Sy.x = sqrt(SS/dof) = sqrt(chi2 / dof)
The question is of course, if SS should be sum of squared errors for the
weighted points, or the non-weighted R2eff points.

Best
Troels

2015-01-19 10:31 GMT+01:00 Edward d'Auvergne &lt;edward@xxxxxxxxxxxxx&gt;:

</pre><blockquote class="blockquote"><pre style="margin: 0em;">Hi Troels,

Do you have a reference for the technique?  You mentioned a 'fitting
guide' in one of your commit messages, but without a reference to it.
I would like to study the technique to understand the implementation.
Does it have another name?  I would guess so as it breaks the
statistical principles that the Monte Carlo simulation technique uses.
That is why the monte_carlo.create_data user function says on the
first line that the technique is called bootstrapping rather than
Monte Carlo simulations if the 'method' argument is changed.   I would
also like to check if it is implemented properly.  For example
accessing the chi2, converting it to the reduced chi2 and using this
as the SSE may not be correct, as the former is normalised by the
errors and the later is not.  You may need to recalculate the SSE as
there is no way to convert from the full/reduced chi2 value to an SSE
value.  I would also like to see if this implementation is a new
methodology that sits beside Monte Carlo simulations and Bootstrapping
simulations, or if it can be used for both of these.

Cheers,

Edward



On 16 January 2015 at 19:13, Edward d'Auvergne &lt;edward@xxxxxxxxxxxxx&gt;
wrote:
</pre><blockquote class="blockquote"><pre style="margin: 0em;">Hi,

Sorry, I meant sum_i(residual_i / error_i)/N &gt; 1.0.  As for
calculating the bias value, it looks like Wikipedia has a reasonable
description (<a  rel="nofollow" href="https://en.wikipedia.org/wiki/Bias_of_an_estimator">https://en.wikipedia.org/wiki/Bias_of_an_estimator</a>).

Regards,

Edward


On 16 January 2015 at 19:07, Edward d'Auvergne &lt;edward@xxxxxxxxxxxxx&gt;
</pre></blockquote><pre style="margin: 0em;">wrote:
</pre><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">Hi,

If you plot the R2eff errors from the Monte Carlo simulations of that
model, are they Gaussian?  Well, that's assuming you have full
dispersion curves.  Theoretically from the white noise in the NMR
spectrum they should be.  Anyway, even if it not claimed that Monte
Carlo simulations have failed, and you have small errors from MC
simulations and large errors from other error analysis technique, and
then pick the large errors, that implies that the Monte Carlo
simulations have failed.  As for using residuals, this is a fall-back
technique when experimental errors have not, or cannot, be measured.
This uses another convergence assumption - if you have infinite data
and the model has a bias value of exactly 0.0, then the residuals
converge to the experimental errors.  For clustering, you might
violate this bias == 0.0 condition (that is almost guaranteed).  You
should also plot your residuals.  If the average residual value is not
0.0, then you have model bias.  Of if you see a trend in the residual
plot.

For using the residuals, how do these values compare to the error
values?  If the residuals are bigger than the experimental error, then
this also indicates that abs(bias) &gt; 0.0.  A scatter plot of R2eff
residuals vs. errors might be quite useful.  This should be a linear
plot with a gradient of 1, anything else indicates bias.  There might
even be a way of calculating the bias value from the residuals and
errors, though I've forgotten how this is done.  Anyway, if you have a
large bias due to the residuals being bigger than the R2eff error,
using the residuals for error analysis is not correct.  It will
introduce larger errors, that is guaranteed.  So you will have the
result that kex has larger errors.  But it is useful to understand the
theoretical reason why.  A large component of that kex error is the
modelling bias.  So if sum_i(residual_i / error_i) &gt; 1.0, then you
likely have under-fitting.  This could be caused by clustering or the
2-site model being insufficient.  In any case, using the residuals for
an error analysis to work around kex errors being too small only
indicates a problem with the data modelling.

What about testing the covariance matrix technique?  I guess that due
to small amounts of data that single-item-out cross validation is not
an option.

Regards,

Edward



On 16 January 2015 at 18:25, Troels Emtekær Linnet
&lt;tlinnet@xxxxxxxxxxxxx&gt; wrote:
</pre><blockquote class="blockquote"><pre style="margin: 0em;">Hi Edward.

I do not claim that &quot;Monte Carlo simulations&quot; is not the gold standard.

I am merely trying to investigate the method by which one draw the
</pre></blockquote></blockquote></blockquote><pre style="margin: 0em;">errors.
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">

In the current case for dispersion, one trust the R2eff errors to be
</pre></blockquote></blockquote></blockquote><pre style="margin: 0em;">the
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">distribution.
These are individual per spin.

Another distribution could be from how well the clustered fit
</pre></blockquote></blockquote></blockquote><pre style="margin: 0em;">performed.
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">And this is what I am looking into.

Best
Troels

2015-01-16 18:09 GMT+01:00 Edward d'Auvergne &lt;edward@xxxxxxxxxxxxx&gt;:
</pre><blockquote class="blockquote"><pre style="margin: 0em;">

Hi,

Do the R2eff errors look reasonable?  Another issue is in clustered
analysis, certain parameters can be over-constrained by being shared
between multiple data sets.  This is the biased introduced by an
under-fitted problem.  This can artificially decrease the errors.
Anyway, you should plot the Monte Carlo simulations, a bit like I did
in figure 4 of my paper:

   d'Auvergne, E. J. and Gooley, P. R. (2006). Model-free model
elimination: A new step in the model-free dynamic analysis of NMR
relaxation data. J. Biomol. NMR, 35(2), 117-135.
(<a  rel="nofollow" href="http://dx.doi.org/10.1007/s10858-006-9007-z">http://dx.doi.org/10.1007/s10858-006-9007-z</a>)

That might indicate if something is wrong - i.e. if optimisation of
certain simulations have failed.  However this problem only causes
errors to be bigger than they should be (unless all simulations have
failed).  I don't know how Monte Carlo simulations could fail
otherwise.  Monte Carlo simulations are the gold standard for error
analysis.  All other error analysis techniques are judged based on how
close the approach this gold standard.  Saying that the Monte Carlo
simulations technique failed is about equivalent to claiming the Earth
is flat!  I challenge you to test the statement on a statistics
professor at your Uni ;)  Anyway, if Monte Carlo failed, using
residuals will not save you as the failure point will be present in
both techniques.  What could have failed is the model or the input
data.  Under-fitting due to too much R2eff data variability in the
spins of the cluster would be my guess.  Do you see similarly small
errors in the non-clustered analysis of the same data?

Regards,

Edward






On 16 January 2015 at 17:48, Troels Emtekær Linnet
&lt;tlinnet@xxxxxxxxxxxxx&gt; wrote:
</pre><blockquote class="blockquote"><pre style="margin: 0em;">Hi Edward.

At the moment, I am fairly confident that I should investigate the
distribution from which the errors are drawn.

The method in relax draws from a Gauss distribution of the R2eff
</pre></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">errors,
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">but
I should try to draw errors from the
overall residual instead.

It is two different methods.

My PI, has earlier has before analysed the data with the
</pre></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">aforementioned
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">method, and got errors in the hundreds.
Errors are 5-10% of the fitted global parameters.

Having 0.5-1 percent error is way to small, and I see this for 4 of
</pre></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">my
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">datasets.

So, something is fishy.

Best
Troels

2015-01-16 17:30 GMT+01:00 Edward d'Auvergne &lt;edward@xxxxxxxxxxxxx
</pre></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">:
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">

Hi Troels,

You should be very careful with your interpretation here.  The
curvature of the chi-squared space does not correlate with the
parameter errors!  Well, it most cases it doesn't.  You will see
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">this
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">if you map the space for different Monte Carlo simulations.  Some
extreme edge cases might help in understanding the problem.  Lets
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">say
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">you have a kex value of 100 with a real error of 1000.  In this
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">case,
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">you could still have a small, perfectly quadratic minimum.  But
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">this
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">minimum will jump all over the place with the simulations.  Another
extreme example might be kex of 100 with a real error of
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">0.00000001.
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">In this case, the chi-squared space could look similar to the
screenshot you attached to the task ( <a  rel="nofollow" href="http://gna.org/task/?7882">http://gna.org/task/?7882</a>).
However Monte Carlo simulations may hardly perturb the chi-squared
space.  I have observed scenarios similar to these hypothetical
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">cases
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">with the Lipari and Szabo model-free protein dynamics analysis.

There is one case where the chi-squared space and error space
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">match,
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">and that is at the limit of the minimum when the chi-squared space
becomes quadratic.  This happens when you zoom right into the
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">minimum.
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">The correlation matrix approach makes this assumption.  Monte Carlo
simulations do not.  In fact, Monte Carlo simulations are the gold
standard.  There is no technique which is better than Monte Carlo
simulations, if you use enough simulations.  You can only match it
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">by
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">deriving exact symbolic error equations.

Therefore you really should investigate how your optimisation
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">space is
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">perturbed by Monte Carlo simulations to understand the correlation
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">-
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">or non-correlation - of the chi-squared curvature and the parameter
errors.  Try mapping the minimum for the simulations and see if the
distribution of minima matches the chi-squared curvature
(<a  rel="nofollow" href="http://gna.org/task/download.php?file_id=23527">http://gna.org/task/download.php?file_id=23527</a>).

Regards,

Edward


On 16 January 2015 at 17:14, Troels E. Linnet
&lt;NO-REPLY.INVALID-ADDRESS@xxxxxxx&gt; wrote:
</pre><blockquote class="blockquote"><pre style="margin: 0em;">URL:
  &lt;<a  rel="nofollow" href="http://gna.org/task/?7882">http://gna.org/task/?7882</a>&gt;

                 Summary: Implement Monte-Carlo simulation, where
errors
are
generated with width of standard deviation or residuals
                 Project: relax
            Submitted by: tlinnet
            Submitted on: Fri 16 Jan 2015 04:14:30 PM UTC
         Should Start On: Fri 16 Jan 2015 12:00:00 AM UTC
   Should be Finished on: Fri 16 Jan 2015 12:00:00 AM UTC
                Category: relax's source code
                Priority: 5 - Normal
                  Status: In Progress
        Percent Complete: 0%
             Assigned to: tlinnet
             Open/Closed: Open
         Discussion Lock: Any
                  Effort: 0.00

    _______________________________________________________

Details:

This is implemented due to strange results.

A relaxation dispersion on data with 61 spins, and a monte carlo
simulation
with 500 steps, showed un-expected low errors.

-------
results.read(file=fname_results, dir=dir_results)

# Number of MC
mc_nr = 500

monte_carlo.setup(number=mc_nr)
monte_carlo.create_data()
monte_carlo.initial_values()
minimise.execute(min_algor='simplex', func_tol=1e-25,
max_iter=int(1e7),
constraints=True)
monte_carlo.error_analysis()
--------

The kex was 2111 and with error 16.6.

When performing a dx.map, some weird results was found:

i_sort    dw_sort    pA_sort    kex_sort      chi2_sort
471       4.50000    0.99375    2125.00000    4664.31083
470       4.50000    0.99375    1750.00000    4665.23872

So, even a small change with chi2, should reflect a larger
deviation with kex.

It seems, that change of R2eff values according to their errors,
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">is
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">not
&quot;enough&quot;.

According to the regression book of Graphpad
<a  rel="nofollow" href="http://www.graphpad.com/faq/file/Prism4RegressionBook.pdf">http://www.graphpad.com/faq/file/Prism4RegressionBook.pdf</a>

Page 33, and 104.
Standard deviation of residuals is:

Sxy = sqrt(SS/(N-p))

where SS is sum of squares. N - p, is the number of degrees of
freedom.
In relax, SS is spin.chi2, and is weighted.

The random scatter to each R2eff point should be drawn from a
gaussian
distribution with a mean of Zero and SD equal to Sxy.

Additional, find the 2.5 and 97.5 percentile for each parameter.
The range between these values is the confidence interval.




    _______________________________________________________

File Attachments:


-------------------------------------------------------
Date: Fri 16 Jan 2015 04:14:30 PM UTC  Name: Screenshot-1.png
</pre></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><pre style="margin: 0em;">Size:
</pre><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><blockquote class="blockquote"><pre style="margin: 0em;">161kB
By: tlinnet

&lt;<a  rel="nofollow" href="http://gna.org/task/download.php?file_id=23527">http://gna.org/task/download.php?file_id=23527</a>&gt;

    _______________________________________________________

Reply to this item at:

  &lt;<a  rel="nofollow" href="http://gna.org/task/?7882">http://gna.org/task/?7882</a>&gt;

_______________________________________________
  Message sent via/by Gna!
  <a  rel="nofollow" href="http://gna.org/">http://gna.org/</a>


_______________________________________________
relax (<a  rel="nofollow" href="http://www.nmr-relax.com">http://www.nmr-relax.com</a>)

This is the relax-devel mailing list
relax-devel@xxxxxxx

To unsubscribe from this list, get a password
reminder, or change your subscription options,
visit the list information page at
<a  rel="nofollow" href="http://www.nmr-relax.com/mail.gna.org/listinfo/relax-devel">https://mail.gna.org/listinfo/relax-devel</a>
</pre></blockquote></blockquote><pre style="margin: 0em;">


</pre></blockquote></blockquote><pre style="margin: 0em;">


</pre></blockquote></blockquote></blockquote><pre style="margin: 0em;">

</pre></blockquote><pre style="margin: 0em;">

</pre>
<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
</div><!-- end msgdata -->
<br />
<h3><a name="related" href="#related">Related Messages</a></h3>
<div class="relateddata">
<ul><li><strong>Follow-Ups</strong>:
<ul>
<li><strong><a name="00059" href="msg00059.html">Re: [task #7882] Implement Monte-Carlo simulation, where errors are generated with width of standard deviation or residuals</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00058" href="msg00058.html">Re: [task #7882] Implement Monte-Carlo simulation, where errors are generated with width of standard deviation or residuals</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
</ul></li></ul>
<!--X-Follow-Ups-End-->
<!--X-References-->
<ul><li><strong>References</strong>:
<ul>
<li><strong><a name="00034" href="msg00034.html">[task #7882] Implement Monte-Carlo simulation, where errors are generated with width of standard deviation or residuals</a></strong>
<ul><li><em>From:</em> Troels E. Linnet</li></ul></li>
<li><strong><a name="00035" href="msg00035.html">Re: [task #7882] Implement Monte-Carlo simulation, where errors are generated with width of standard deviation or residuals</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00036" href="msg00036.html">Re: [task #7882] Implement Monte-Carlo simulation, where errors are generated with width of standard deviation or residuals</a></strong>
<ul><li><em>From:</em> Troels Emtekær Linnet</li></ul></li>
<li><strong><a name="00037" href="msg00037.html">Re: [task #7882] Implement Monte-Carlo simulation, where errors are generated with width of standard deviation or residuals</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00038" href="msg00038.html">Re: [task #7882] Implement Monte-Carlo simulation, where errors are generated with width of standard deviation or residuals</a></strong>
<ul><li><em>From:</em> Troels Emtekær Linnet</li></ul></li>
<li><strong><a name="00039" href="msg00039.html">Re: [task #7882] Implement Monte-Carlo simulation, where errors are generated with width of standard deviation or residuals</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00040" href="msg00040.html">Re: [task #7882] Implement Monte-Carlo simulation, where errors are generated with width of standard deviation or residuals</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00049" href="msg00049.html">Re: [task #7882] Implement Monte-Carlo simulation, where errors are generated with width of standard deviation or residuals</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
</ul></li></ul>
<!--X-References-End-->
<!--X-BotPNI-->
</div><!-- end relateddata -->
<!-- NoBotLinksApartFromRelatedMessages -->

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->
<div class="footer"></div><br />
<div class="right">Powered by <a href="http://www.mhonarc.org">MHonArc</a>, Updated Mon Jan 19 19:00:12 2015</div>  
</body>
</html>
