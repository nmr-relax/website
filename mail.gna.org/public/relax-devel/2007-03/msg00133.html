<!-- MHonArc v2.6.10 -->
<!--X-Subject: Fwd: how to parallelise model_free minimise -->
<!--X-From-R13: "tnel gubzcfba" <tnelgNozo.yrrqf.np.hx> -->
<!--X-Date: Tue, 27 Mar 2007 09:23:06 +0200 -->
<!--X-Message-Id: f001463a0703270022iec6830fs2aec68f942d16cb2@mail.gmail.com -->
<!--X-Content-Type: text/plain -->
<!--X-Reference: 7f080ed10703191030h79036e06w56912aa1d9130f48@mail.gmail.com -->
<!--X-Reference: 45FFEC5C.7060205@bmb.leeds.ac.uk -->
<!--X-Reference: 7f080ed10703200727l5fad8e72if4cf9aff74bc21@mail.gmail.com -->
<!--X-Reference: 45FFF714.7070903@bmb.leeds.ac.uk -->
<!--X-Reference: 7f080ed10703200813x323ec212l471796641855a7ff@mail.gmail.com -->
<!--X-Reference: 4603EA08.60801@bmb.leeds.ac.uk -->
<!--X-Reference: 7f080ed10703252217x7db43e6bxfe7324ad0379c778@mail.gmail.com -->
<!--X-Reference: 4607F0AB.6000807@bmb.leeds.ac.uk -->
<!--X-Reference: 7f080ed10703261002i7cc384a6n8bf20be7aaad4e0e@mail.gmail.com -->
<!--X-Reference: f001463a0703270015n76d1b728m749f70fba54d8213@mail.gmail.com -->
<!--X-Head-End-->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>Fwd: how to parallelise model_free minimise -- March 27, 2007 - 09:23</title>
<link rel="stylesheet" type="text/css" href="/mail.gna.org/archives-color-gna.css"> 
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>
<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->
<h2><img src="/mail.gna.org/images/mail.orig.png" width="48" height="48"
alt="mail" class="pageicon" />Fwd: how to parallelise model_free minimise</h2>
<br />
<div class="topmenu">
<a href="../" class="tabs">Others Months</a> | <a href="index.html#00133" class="tabs">Index by Date</a> | <a href="threads.html#00133" class="tabs">Thread Index</a><br />
<span class="smaller">&gt;&gt;&nbsp;&nbsp;
[<a href="msg00132.html">Date Prev</a>] [<a href="msg00134.html">Date Next</a>] [<a href="msg00131.html">Thread Prev</a>] [<a href="msg00136.html">Thread Next</a>]
</div>

<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->
<h3><a name="header" href="#header">Header</a></h3>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->
<ul class="headdata">
<li class="menuitem">
<em>To</em>: relax-devel@xxxxxxx</li>
<li class="menuitem">
<em>Date</em>: Tue, 27 Mar 2007 08:22:30 +0100</li>
<li class="menuitem">
<em>Dkim-signature</em>: a=rsa-sha1; c=relaxed/relaxed; d=gmail.com; s=beta;	h=domainkey-signature:received:received:message-id:date:from:sender:to:subject:in-reply-to:mime-version:content-type:content-transfer-encoding:content-disposition:references:x-google-sender-auth;	b=iQuvtrMbytJCj1Ac+hgeTi2/p374tMpmj+0GTK3oF9SV9hPzFA9ZTueOv6Lx/jJapdO2aXssBmHzjLo+rOoR1d+/3YLA2dB9OLRGRVpae4thYdcdQTQpNixU/qYBRFpdxfDDT/tDLBJhunkOGtcfkrumvLlwRE7oJ4UMJlaa71U=</li>
<li class="menuitem">
<em>Message-id</em>: &lt;<a href="msg00133.html">f001463a0703270022iec6830fs2aec68f942d16cb2@mail.gmail.com</a>&gt;</li>
<li class="menuitem">
<em>References</em>: &lt;<a href="msg00092.html">7f080ed10703191030h79036e06w56912aa1d9130f48@mail.gmail.com</a>&gt;	&lt;<a href="msg00107.html">45FFEC5C.7060205@bmb.leeds.ac.uk</a>&gt;	&lt;<a href="msg00110.html">7f080ed10703200727l5fad8e72if4cf9aff74bc21@mail.gmail.com</a>&gt;	&lt;<a href="msg00112.html">45FFF714.7070903@bmb.leeds.ac.uk</a>&gt;	&lt;<a href="msg00114.html">7f080ed10703200813x323ec212l471796641855a7ff@mail.gmail.com</a>&gt;	&lt;<a href="msg00124.html">4603EA08.60801@bmb.leeds.ac.uk</a>&gt;	&lt;<a href="msg00126.html">7f080ed10703252217x7db43e6bxfe7324ad0379c778@mail.gmail.com</a>&gt;	&lt;<a href="msg00128.html">4607F0AB.6000807@bmb.leeds.ac.uk</a>&gt;	&lt;<a href="msg00129.html">7f080ed10703261002i7cc384a6n8bf20be7aaad4e0e@mail.gmail.com</a>&gt;	&lt;<a href="msg00131.html">f001463a0703270015n76d1b728m749f70fba54d8213@mail.gmail.com</a>&gt;</li>
</ul>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
</div><!-- end headdata -->
<br />
<h3><a name="content" href="#content">Content</a></h3>
<div class="postedby">Posted by <strong>gary thompson</strong> on March 27, 2007 - 09:23:</div>
<div class="msgdata">
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<tt>On 3/26/07, Edward d'Auvergne &lt;edward@xxxxxxxxxxxxx&gt; wrote:
</tt><blockquote class="blockquote"><pre style="margin: 0em;">On 3/27/07, Gary S. Thompson &lt;garyt@xxxxxxxxxxxxxxx&gt; wrote:
&gt; Edward d'Auvergne wrote:
&gt; &gt; On 3/24/07, Gary S. Thompson &lt;garyt@xxxxxxxxxxxxxxx&gt; wrote:</pre><br>
<pre style="margin: 0em;">&gt; &gt;&gt; 2. what is going to change between runs or even over runs of the relax
&gt; &gt;&gt; program.
&gt; &gt;
&gt; &gt; For each iteration of the main loop, these arguments and parameters
&gt; &gt; will change.
&gt; &gt;
&gt; Not necessarily? certainly things such as remap_table, ri_labels, etc do
&gt; not seem to change between passes through the loop</pre><br>
<pre style="margin: 0em;">These actually change if you have a data set missing for a single spin
system because of peak overlap, etc.  Most of the time you don't see
this though.</pre><br>
<br>
</blockquote><pre style="margin: 0em;"><br>Ah now I see! Well the answer here is to preprocess the data in the
master process
minimise  loop and look for shared instances and only send
the shared instances over the wire along with some tokens defining
what to replace with what. Then we put it all back together at the end
(i.e. we unshare things  by replacing tokens with unique instances
(this is a form of the flyweight pattern in one way but not another)</pre><br>
<blockquote class="blockquote"><pre style="margin: 0em;">&gt; &gt;&gt; As an aside when the redesign of the spin_loops and minimise /model
&gt; &gt;&gt; loops cuts in it would be a good idea 9from the paralle point of view)
&gt; &gt;&gt; to have the spin loop  running faster than the minimse/model loop
&gt; &gt;
&gt; Sorry I wasn't quite clear here, its not comuptational speed I am
&gt; talking about but the speed of the 'loop counter'</pre><br>
<pre style="margin: 0em;">Sorry, I don't quite understand what the speed of a 'loop counter' is.</pre><br>
<br>
</blockquote><pre style="margin: 0em;"><br>loop counter: a number that increases linearly each time you make a
new pass through the loop</pre><br>
<blockquote class="blockquote"><pre style="margin: 0em;">&gt; e.g.it would be nice to have
&gt;
&gt; for residue in  all residues:
&gt;     for model in models:
&gt;              do_stuff-(tm)
&gt;
&gt;
&gt; as opposed to
&gt;
&gt; for model in models: #currently at the user level
&gt;     for residue in  all residues:
&gt;              do_stuff-(tm)
&gt;
&gt; now that might need something of the form
&gt;
&gt;         # Set the run names (also the names of preset model-free models).
&gt;         if local_tm:
&gt;             self.runs = ['tm0', 'tm1', 'tm2', 'tm3', 'tm4', 'tm5',
&gt; 'tm6', 'tm7', 'tm8', 'tm9']
&gt;         else:
&gt;             self.runs = ['m0', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7',
&gt; 'm8', 'm9']
&gt;
&gt; run.create_composite('super')
&gt; for name in self.runs:
&gt;
&gt;     run.create(name, 'mf')
&gt;     composite_add('super',name)
&gt;     minimise('newton', run='super')
&gt;
&gt;
&gt; which would minimise all runs in parallel...
&gt;
&gt; and I understand from chris that we are planning to do
&gt;
&gt;
&gt;        # Set the run names (also the names of preset model-free models).
&gt;         if local_tm:
&gt;             self.runs = ['tm0', 'tm1', 'tm2', 'tm3', 'tm4', 'tm5',
&gt; 'tm6', 'tm7', 'tm8', 'tm9']
&gt;         else:
&gt;             self.runs = ['m0', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7',
&gt; 'm8', 'm9']
&gt;
&gt;
&gt;      minimise('newton', runs=self.runs)
&gt;
&gt;
&gt; which would also work
&gt;
&gt;
&gt; now comes the tricky bit
&gt;
&gt;
&gt; all the minimisations etc would now become rfnctions to setup
&gt; minimsations and say submit them to a queue with a suitable object to
&gt; allow the results to be sorted out later.
&gt;
&gt; then at the end of minimise('newton', runs=self.runs) you would collect
&gt; in all the results from all calculations and complete the calculation so
&gt; we have something like
&gt;
&gt; for residue
&gt;     for run in runs:
&gt;        calculation-instance = setup-calculation(residue,run)
&gt;        queue.submit(calculation-instance)
&gt; while(queue.not_complete()):
&gt;     result.queue.get_result()
&gt;     result.record(self.reax.data)
&gt;
&gt; This will allow the maximum numer of calculations to be conducted in
&gt; parallel and will intrisically load balance as well as we can get</pre><br>
<pre style="margin: 0em;">There are a number of very important issues with this approach.  The
most important is that the loop over the data pipes corresponding to
the model-free models (the 'runs') is deliberately not part of the
relax codebase.  In Chris' implementation of the 'runs' argument
(which will need to be renamed) the loop will be at the highest level
of the code so that for the generic_fns.minimise code onwards nothing
changes.  This high level loop would probably be a very difficult
target for MPI as the whole relax data storage object will need to be
sent between nodes.  This multi-megabyte transfer per node, per
calculation is not ideal.</pre><br>
</blockquote><pre style="margin: 0em;">no you wouldn't have to if put the whole thing over the wire as long
as you add calculations to do to a queue at the low level and then
requested the calculations  be completed at the end  of the high level
function. In the end of it the user and program see no difference its
a bit like how an optimising compiler works I guess....</pre><br>
<br>
<blockquote class="blockquote"><pre style="margin: 0em;">Secondly, and very importantly, relax doesn't loop over residues in
the model-free minimise() function.  relax loops over minimisation
instances.  For the 'mf' and 'local_tm' parameter sets, this is a loop
over the spin systems (i.e. molecules first, residues second, and spin
systems last).  For the 'diff' and 'all' parameters sets the number of
minimisation instances is one and hence the loop runs once and then
that's it.  Looping over these followed by looping over the data pipes
(ex-runs) is insane!  That is essentially first looping over the
finest grained level followed by the coarsest.
</pre></blockquote><pre style="margin: 0em;"><br>I do not quite follow where the insanity comes from ;-)</pre><br>
<pre style="margin: 0em;">It is not problem...  What is required is to pass as few chunks of
data with the largest size and best balance of computations over the
wire...  Essentially  I want to (effectively, not literally) build a
list of residues and divide the residues out roughly by processor and
then find all the models required for each residue set them up the
whole set of calculations chunk the whole list by the number of
processors say *3 and then put all these calculations on a queue then
collect the results and put the results where they need to be.
Basically i am saying that in many cases minimisation instances and
runs are disjoint sets and so can be calculated at the same time e.g.
the result of residue3 run tm0 does not affect the result of residue 3
tm1 etc ....
</pre><blockquote class="blockquote"><pre style="margin: 0em;"><br>If you target the main loop of the minimise() code, I can guarrantee
you'll get the best usage out of a cluster.  Without specifically
mentioning this main loop, this is the target we have been talking
about throughout this thread.  An added benefit is that the minimise()
code base hardly needs to be changed.</pre><br>
</blockquote><pre style="margin: 0em;">indeed and the same would be true for the slightly more sophisticated
scheme I have just posited. almost all the changes would be at the
minimise level apart from asking the queue to do all the calculations
;-)</pre><br>
<pre style="margin: 0em;">regards
gary</pre><br>
<blockquote class="blockquote"><pre style="margin: 0em;">Regards,</pre><br>
<pre style="margin: 0em;">Edward</pre><br>
<pre style="margin: 0em;">_______________________________________________
relax (<a  href="http://nmr-relax.com">http://nmr-relax.com</a>)</pre><br>
<pre style="margin: 0em;">This is the relax-devel mailing list
relax-devel@xxxxxxx</pre><br>
<pre style="margin: 0em;">To unsubscribe from this list, get a password
reminder, or change your subscription options,
visit the list information page at
<a  href="http://www.nmr-relax.com/mail.gna.org/listinfo/relax-devel">https://mail.gna.org/listinfo/relax-devel</a></pre><br>
</blockquote><pre style="margin: 0em;"><br></pre><br>

<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
</div><!-- end msgdata -->
<br />
<h3><a name="related" href="#related">Related Messages</a></h3>
<div class="relateddata">
<ul><li><strong>Follow-Ups</strong>:
<ul>
<li><strong><a name="00139" href="msg00139.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00136" href="msg00136.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
</ul></li></ul>
<!--X-Follow-Ups-End-->
<!--X-References-->
<ul><li><strong>References</strong>:
<ul>
<li><strong><a name="00092" href="msg00092.html">relax and Grid computing.</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00107" href="msg00107.html">Re: relax, MPI, and Grid computing.</a></strong>
<ul><li><em>From:</em> Gary S. Thompson</li></ul></li>
<li><strong><a name="00110" href="msg00110.html">Re: relax, MPI, and Grid computing.</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00112" href="msg00112.html">Re: relax, MPI, and Grid computing.</a></strong>
<ul><li><em>From:</em> Gary S. Thompson</li></ul></li>
<li><strong><a name="00114" href="msg00114.html">Re: relax, MPI, and Grid computing.</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00124" href="msg00124.html">how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Gary S. Thompson</li></ul></li>
<li><strong><a name="00126" href="msg00126.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00128" href="msg00128.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Gary S. Thompson</li></ul></li>
<li><strong><a name="00129" href="msg00129.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00131" href="msg00131.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> gary thompson</li></ul></li>
</ul></li></ul>
<!--X-References-End-->
<!--X-BotPNI-->
</div><!-- end relateddata -->
<!-- NoBotLinksApartFromRelatedMessages -->

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->
<div class="footer"></div><br />
<div class="right">Powered by <a href="http://www.mhonarc.org">MHonArc</a>, Updated Tue Mar 27 18:23:13 2007</div>  
</body>
</html>
