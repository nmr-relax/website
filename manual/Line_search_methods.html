<!DOCTYPE HTML>

<!--Converted with LaTeX2HTML 2019 (Released January 1, 2019) -->
<HTML lang="EN">
<HEAD>
<TITLE>Line search methods</TITLE>
<META NAME="description" CONTENT="Line search methods">
<META NAME="keywords" CONTENT="relax">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="viewport" CONTENT="width=device-width, initial-scale=1.0">

  <!--Google analytics JS-->
  <script type="text/javascript">
  
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-30096326-1']);
    _gaq.push(['_setDomainName', 'nmr-relax.com']);
    _gaq.push(['_trackPageview']);
  
    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  
  </script>

<LINK REL="STYLESHEET" HREF="relax.css">

<LINK REL="next" HREF="Trust_region_methods.html">
<LINK REL="previous" HREF="Optimisation_algorithms.html">
<LINK REL="next" HREF="Trust_region_methods.html">
</HEAD>

<BODY >

<DIV CLASS="navigation"><!--Navigation Panel-->
<A
 HREF="Trust_region_methods.html">
<IMG WIDTH="48" HEIGHT="48" TITLE="Next" ALT="next" SRC="next.png"></A> 
<A
 HREF="Optimisation_algorithms.html">
<IMG WIDTH="48" HEIGHT="48" TITLE="Up" ALT="up" SRC="up.png"></A> 
<A
 HREF="Optimisation_algorithms.html">
<IMG WIDTH="48" HEIGHT="48" TITLE="Previous" ALT="previous" SRC="prev.png"></A> 
<A ID="tex2html7626"
  HREF="Contents.html">
<IMG WIDTH="48" HEIGHT="48" TITLE="Contents" ALT="contents" SRC="contents.png"></A> 
<A ID="tex2html7628"
  HREF="Index.html">
<IMG WIDTH="48" HEIGHT="48" TITLE="Index" ALT="index" SRC="index.png"></A> <A ID="tex2html1"
  HREF="https://sourceforge.net/projects/nmr-relax/files/manual/relax.pdf/download"><IMG STYLE="" SRC="http://www.nmr-relax.com/images/pdf_icon_nav.png"
 ALT="pdf_icon_nav.png"></A><A ID="tex2html2"
  HREF="http://www.nmr-relax.com"><IMG STYLE="" SRC="http://www.nmr-relax.com/images/relax_logo_nav.png"
 ALT="relax_logo_nav.png"></A>
<BR>
<B> Next:</B> <A
 HREF="Trust_region_methods.html">Trust region methods</A>
<B> Up:</B> <A
 HREF="Optimisation_algorithms.html">Optimisation algorithms</A>
<B> Previous:</B> <A
 HREF="Optimisation_algorithms.html">Optimisation algorithms</A>
 &nbsp; <B>  <A ID="tex2html7627"
  HREF="Contents.html">Contents</A></B> 
 &nbsp; <B>  <A ID="tex2html7629"
  HREF="Index.html">Index</A></B> 
<BR>
<BR></DIV>
<!--End of Navigation Panel-->
<!--Table of Child-Links-->
<A ID="CHILD_LINKS"><STRONG>Subsections</STRONG></A>

<UL CLASS="ChildLinks">
<LI><A ID="tex2html7630"
  HREF="Line_search_methods.html#SECTION07141100000000000000">The steepest descent algorithm</A>
<LI><A ID="tex2html7631"
  HREF="Line_search_methods.html#SECTION07141200000000000000">The coordinate descent algorithm</A>
<LI><A ID="tex2html7632"
  HREF="Line_search_methods.html#SECTION07141300000000000000">The BFGS algorithm</A>
<LI><A ID="tex2html7633"
  HREF="Line_search_methods.html#SECTION07141400000000000000">The Newton algorithm</A>
<LI><A ID="tex2html7634"
  HREF="Line_search_methods.html#SECTION07141500000000000000">The Newton conjugate gradient algorithm</A>
<LI><A ID="tex2html7635"
  HREF="Line_search_methods.html#SECTION07141600000000000000">The auxiliary step-length selection algorithm</A>
</UL>
<!--End of Table of Child-Links-->
<HR>

<H2><A ID="SECTION07141000000000000000">
Line search methods</A>
</H2>

<P>
The defining characteristic of a line search algorithm is to choose a search direction <SPAN CLASS="MATH"><I>p</I><SUB>k</SUB></SPAN> and then to find the minimum along that vector starting from <SPAN CLASS="MATH"><I>&#952;</I><SUB>k</SUB></SPAN> (<A
 HREF="Bibliography.html#NocedalWright99">Nocedal and Wright, 1999</A>).
The distance travelled along <SPAN CLASS="MATH"><I>p</I><SUB>k</SUB></SPAN> is the step length <SPAN CLASS="MATH"><I>&#945;</I><SUB>k</SUB></SPAN> and the parameter values for the next iteration are
<P></P>
<DIV CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\theta_{k+1} = \theta_k + \alpha_k p_k.
\end{equation}
 -->
<TABLE CLASS="equation" >
<TR>
<TD  style="text-align:center;"><SPAN CLASS="MATH"><I>&#952;</I><SUB>k+1</SUB> = <I>&#952;</I><SUB>k</SUB> + <I>&#945;</I><SUB>k</SUB><I>p</I><SUB>k</SUB>.</SPAN></TD>
<TD  CLASS="eqno" style="text-align:right">
(<SPAN CLASS="arabic">14</SPAN>.<SPAN CLASS="arabic">7</SPAN>)</TD></TR>
</TABLE></DIV>
<P></P>

<P>
The line search algorithm determines the search direction <SPAN CLASS="MATH"><I>p</I><SUB>k</SUB></SPAN> whereas the value of <SPAN CLASS="MATH"><I>&#945;</I><SUB>k</SUB></SPAN> is found using an auxiliary step-length selection algorithm.

<P>

<H3><A ID="SECTION07141100000000000000"></A>
<A ID="24834"></A>
<BR>
The steepest descent algorithm
</H3>

<P>
One of the simplest line search methods is the steepest descent algorithm.
The search direction is simply the negative gradient, <!-- MATH
 $p_k = -\nabla f_k$
 -->
<SPAN CLASS="MATH"><I>p</I><SUB>k</SUB> = - &#8711;<I>f</I><SUB>k</SUB></SPAN>, and hence the direction of maximal descent is always followed.
This method is inefficient - the linear rate of convergence requires many iterations of the algorithm to reach the minimum and it is susceptible to being trapped on saddle points within the space.

<P>

<H3><A ID="SECTION07141200000000000000"></A>
<A ID="24836"></A>
<BR>
The coordinate descent algorithm
</H3>

<P>
The coordinate descent algorithms are a simplistic group of line search methods whereby the search directions alternate between vectors parallel to the parameter axes.
For the back-and-forth coordinate descent the search directions cycle in one direction and then back again.
For example for a three parameter model the search directions cycle <!-- MATH
 $\theta_1, \theta_2, \theta_3, \theta_2, \theta_1, \theta_2, \hdots$
 -->
<SPAN CLASS="MATH"><I>&#952;</I><SUB>1</SUB>, <I>&#952;</I><SUB>2</SUB>, <I>&#952;</I><SUB>3</SUB>, <I>&#952;</I><SUB>2</SUB>, <I>&#952;</I><SUB>1</SUB>, <I>&#952;</I><SUB>2</SUB>,</SPAN>, which means that each parameter of the model is optimised one by one.
The method becomes less efficient when approaching the minimum as the step length <SPAN CLASS="MATH"><I>&#945;</I><SUB>k</SUB></SPAN> continually decreases (ibid.).

<P>

<H3><A ID="SECTION07141300000000000000"></A>
<A ID="24838"></A>
<BR>
The BFGS algorithm
</H3>

<P>
The quasi-Newton methods begin with an initial guess of the Hessian and update it at each iteration using the function value and gradient.
Therefore the benefits of using the quadratic model of (<A HREF="The_Hessian.html#eq:_quadratic_model">14.5</A>) are obtained without calculating the computationally expensive Hessian.
The Hessian approximation <SPAN CLASS="MATH"><I>B</I><SUB>k</SUB></SPAN> is updated using various formulae, the most common being the BFGS formula (<A ID="tex2html7636" target="contents"
  HREF="Bibliography.html#Broyden70">Broyden, 1970</A>; <A ID="tex2html7637" target="contents"
  HREF="Bibliography.html#Shanno70">Shanno, 1970</A>; <A ID="tex2html7638" target="contents"
  HREF="Bibliography.html#Fletcher70">Fletcher, 1970</A>; <A ID="tex2html7639" target="contents"
  HREF="Bibliography.html#Goldfarb70">Goldfarb, 1970</A>).
The search direction is given by the equation <!-- MATH
 $p_k = -B_k^{-1} \nabla f_k$
 -->
<SPAN CLASS="MATH"><I>p</I><SUB>k</SUB> = - <I>B</I><SUB>k</SUB><SUP>-1</SUP>&#8711;<I>f</I><SUB>k</SUB></SPAN>.
The quasi-Newton algorithms can attain a superlinear rate of convergence, being superior to the steepest descent or coordinate descent methods.

<P>

<H3><A ID="SECTION07141400000000000000"></A>
<A ID="24843"></A>
<BR>
The Newton algorithm
</H3>

<P>
The most powerful line search method when close to the minimum is the Newton search direction
<P></P>
<DIV CLASS="mathdisplay"><A ID="eq:_Newton_dir"></A><!-- MATH
 \begin{equation}
p_k = - \nabla^2 f_k^{-1} \nabla f_k.
\end{equation}
 -->
<TABLE CLASS="equation" >
<TR>
<TD  style="text-align:center;"><SPAN CLASS="MATH"><I>p</I><SUB>k</SUB> = - &#8711;<SUP>2</SUP><I>f</I><SUB>k</SUB><SUP>-1</SUP>&#8711;<I>f</I><SUB>k</SUB>.</SPAN></TD>
<TD  CLASS="eqno" style="text-align:right">
(<SPAN CLASS="arabic">14</SPAN>.<SPAN CLASS="arabic">8</SPAN>)</TD></TR>
</TABLE></DIV>
<P></P>

<P>
This direction is obtained from the derivative of (<A HREF="The_Hessian.html#eq:_quadratic_model">14.5</A>) which is assumed to be zero at the minimum of the quadratic model.
The vector <SPAN CLASS="MATH"><I>p</I><SUB>k</SUB></SPAN> points from the current position to the exact minimum of the quadratic model of the space.
The rate of convergence is quadratic, being superior to both linear and superlinear convergence.
The technique is computationally expensive due to the calculation of the Hessian.
It is also susceptible to failure when optimisation commences from distant positions in the space as the Hessian may not be positive definite and hence not convex, a condition required for the search direction both to point downhill and to be reasonably oriented.
In these cases the quadratic model is a poor description of the space.
This algorithm is also known as the Newton-Raphson method.

<P>

<H3><A ID="SECTION07141500000000000000"></A>
<A ID="24850"></A>
<BR>
The Newton conjugate gradient algorithm
</H3>

<P>
A practical Newton algorithm which is robust for distant starting points is the Newton conjugate gradient method (Newton-CG).
This line search method, which is also called the truncated Newton algorithm, finds an approximate solution to Equation&nbsp;(<A HREF="#eq:_Newton_dir">14.8</A>) by using a conjugate gradient (CG) sub-algorithm.
Retaining the performance of the pure Newton algorithm, the CG sub-algorithm guarantees that the search direction is always downhill as the method terminates when negative curvature is encountered.

<P>

<H3><A ID="SECTION07141600000000000000"></A>
<A ID="24853"></A>
<BR>
The auxiliary step-length selection algorithm
</H3>

<P>
Once the search direction has been determined by the above algorithms the minimum along that direction needs to be determined.
Not to be confused with the methodology for determining the search direction <SPAN CLASS="MATH"><I>p</I><SUB>k</SUB></SPAN>, the line search itself is performed by an auxiliary step-length selection algorithm to find the value <SPAN CLASS="MATH"><I>&#945;</I><SUB>k</SUB></SPAN>.
A number of step-length selection methods can be used to find a minimum along the line <!-- MATH
 $\theta_k + \alpha_k p_k$
 -->
<SPAN CLASS="MATH"><I>&#952;</I><SUB>k</SUB> + <I>&#945;</I><SUB>k</SUB><I>p</I><SUB>k</SUB></SPAN>.
One is the backtracking line search of <A
 HREF="Bibliography.html#NocedalWright99">Nocedal and Wright (1999)</A>.
This method is inexact - it takes a starting step length <SPAN CLASS="MATH"><I>&#945;</I><SUB>k</SUB></SPAN> and decreases the value until a sufficient decrease in the function is found.
Another is the line search method of <A
 HREF="Bibliography.html#MoreThuente94">Mor&#233; and Thuente (1994)</A>.
Designed to be robust, the MT algorithm finds the exact minimum along the search direction and guarantees sufficient decrease.

<P>

<DIV CLASS="navigation"><HR>
<!--Navigation Panel-->
<A
 HREF="Trust_region_methods.html">
<IMG WIDTH="48" HEIGHT="48" TITLE="Next" ALT="next" SRC="next.png"></A> 
<A
 HREF="Optimisation_algorithms.html">
<IMG WIDTH="48" HEIGHT="48" TITLE="Up" ALT="up" SRC="up.png"></A> 
<A
 HREF="Optimisation_algorithms.html">
<IMG WIDTH="48" HEIGHT="48" TITLE="Previous" ALT="previous" SRC="prev.png"></A> 
<A ID="tex2html7626"
  HREF="Contents.html">
<IMG WIDTH="48" HEIGHT="48" TITLE="Contents" ALT="contents" SRC="contents.png"></A> 
<A ID="tex2html7628"
  HREF="Index.html">
<IMG WIDTH="48" HEIGHT="48" TITLE="Index" ALT="index" SRC="index.png"></A> <A ID="tex2html1"
  HREF="https://sourceforge.net/projects/nmr-relax/files/manual/relax.pdf/download"><IMG STYLE="" SRC="http://www.nmr-relax.com/images/pdf_icon_nav.png"
 ALT="pdf_icon_nav.png"></A><A ID="tex2html2"
  HREF="http://www.nmr-relax.com"><IMG STYLE="" SRC="http://www.nmr-relax.com/images/relax_logo_nav.png"
 ALT="relax_logo_nav.png"></A>
<BR>
<B> Next:</B> <A
 HREF="Trust_region_methods.html">Trust region methods</A>
<B> Up:</B> <A
 HREF="Optimisation_algorithms.html">Optimisation algorithms</A>
<B> Previous:</B> <A
 HREF="Optimisation_algorithms.html">Optimisation algorithms</A>
 &nbsp; <B>  <A ID="tex2html7627"
  HREF="Contents.html">Contents</A></B> 
 &nbsp; <B>  <A ID="tex2html7629"
  HREF="Index.html">Index</A></B> </DIV>
<!--End of Navigation Panel-->
<ADDRESS>
The <a href="http://www.nmr-relax.com">relax</a> <a href="http://www.nmr-relax.com/manual/">user manual</a> (<a href="https://sourceforge.net/projects/nmr-relax/files/manual/relax.pdf/download">PDF</a>), created 2024-06-08.
</ADDRESS>
</BODY>
</HTML>
