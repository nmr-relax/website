<!-- MHonArc v2.6.10 -->
<!--X-Subject: Re: how to parallelise model_free minimise -->
<!--X-From-R13: "tnel gubzcfba" <tnelg.naq.fnenuoNtznvy.pbz> -->
<!--X-Date: Tue, 27 Mar 2007 21:19:31 +0200 -->
<!--X-Message-Id: f001463a0703271218n67b2f3a3oe5aff06a4810d178@mail.gmail.com -->
<!--X-Content-Type: text/plain -->
<!--X-Reference: 7f080ed10703191030h79036e06w56912aa1d9130f48@mail.gmail.com -->
<!--X-Reference: 45FFF714.7070903@bmb.leeds.ac.uk -->
<!--X-Reference: 7f080ed10703200813x323ec212l471796641855a7ff@mail.gmail.com -->
<!--X-Reference: 4603EA08.60801@bmb.leeds.ac.uk -->
<!--X-Reference: 7f080ed10703252217x7db43e6bxfe7324ad0379c778@mail.gmail.com -->
<!--X-Reference: 4607F0AB.6000807@bmb.leeds.ac.uk -->
<!--X-Reference: 7f080ed10703261002i7cc384a6n8bf20be7aaad4e0e@mail.gmail.com -->
<!--X-Reference: f001463a0703270015n76d1b728m749f70fba54d8213@mail.gmail.com -->
<!--X-Reference: f001463a0703270022iec6830fs2aec68f942d16cb2@mail.gmail.com -->
<!--X-Reference: 7f080ed10703270907h3e882251v6b66b329ecfeb910@mail.gmail.com -->
<!--X-Head-End-->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>Re: how to parallelise model_free minimise -- March 27, 2007 - 21:19</title>
<link rel="stylesheet" type="text/css" href="/archives-color-gna.css"> 
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>
<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->
<h2><img src="https://gna.org/images/gna.theme/mail.orig.png" width="48" height="48"
alt="mail" class="pageicon" />Re: how to parallelise model_free minimise</h2>
<br />
<div class="topmenu">
<a href="../" class="tabs">Others Months</a> | <a href="index.html#00144" class="tabs">Index by Date</a> | <a href="threads.html#00144" class="tabs">Thread Index</a><br />
<span class="smaller">&gt;&gt;&nbsp;&nbsp;
[<a href="msg00143.html">Date Prev</a>] [<a href="msg00145.html">Date Next</a>] [<a href="msg00139.html">Thread Prev</a>] [<a href="msg00145.html">Thread Next</a>]
</div>

<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->
<h3><a name="header" href="#header">Header</a></h3>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->
<ul class="headdata">
<li class="menuitem">
<em>To</em>: &quot;Edward d'Auvergne&quot; &lt;edward.dauvergne@xxxxxxxxx&gt;</li>
<li class="menuitem">
<em>Date</em>: Tue, 27 Mar 2007 20:18:52 +0100</li>
<li class="menuitem">
<em>Cc</em>: relax-devel@xxxxxxx</li>
<li class="menuitem">
<em>Dkim-signature</em>: a=rsa-sha1; c=relaxed/relaxed; d=gmail.com; s=beta;	h=domainkey-signature:received:received:message-id:date:from:to:subject:cc:in-reply-to:mime-version:content-type:content-transfer-encoding:content-disposition:references;	b=pqRfhYLTCh44/otilcWhZ8erWlxPUXDtFToEggcfhLtg5eHF534slKUA/1pdBKnaD2xjHKTNjJNYSlVpfP5azrEjdXMcvbM1SV3vrTVkRzMpoh4pCDdV7vg3IpmAjC+cmrQZISY9q8ljqCbAz4d6D1umpmx9UBZOy2TlzJ9GdIo=</li>
<li class="menuitem">
<em>Message-id</em>: &lt;<a href="msg00144.html">f001463a0703271218n67b2f3a3oe5aff06a4810d178@mail.gmail.com</a>&gt;</li>
<li class="menuitem">
<em>References</em>: &lt;<a href="msg00092.html">7f080ed10703191030h79036e06w56912aa1d9130f48@mail.gmail.com</a>&gt;	&lt;<a href="msg00112.html">45FFF714.7070903@bmb.leeds.ac.uk</a>&gt;	&lt;<a href="msg00114.html">7f080ed10703200813x323ec212l471796641855a7ff@mail.gmail.com</a>&gt;	&lt;<a href="msg00124.html">4603EA08.60801@bmb.leeds.ac.uk</a>&gt;	&lt;<a href="msg00126.html">7f080ed10703252217x7db43e6bxfe7324ad0379c778@mail.gmail.com</a>&gt;	&lt;<a href="msg00128.html">4607F0AB.6000807@bmb.leeds.ac.uk</a>&gt;	&lt;<a href="msg00129.html">7f080ed10703261002i7cc384a6n8bf20be7aaad4e0e@mail.gmail.com</a>&gt;	&lt;<a href="msg00131.html">f001463a0703270015n76d1b728m749f70fba54d8213@mail.gmail.com</a>&gt;	&lt;<a href="msg00133.html">f001463a0703270022iec6830fs2aec68f942d16cb2@mail.gmail.com</a>&gt;	&lt;<a href="msg00139.html">7f080ed10703270907h3e882251v6b66b329ecfeb910@mail.gmail.com</a>&gt;</li>
</ul>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
</div><!-- end headdata -->
<br />
<h3><a name="content" href="#content">Content</a></h3>
<div class="postedby">Posted by <strong>gary thompson</strong> on March 27, 2007 - 21:19:</div>
<div class="msgdata">
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<tt>On 3/27/07, Edward d'Auvergne &lt;edward.dauvergne@xxxxxxxxx&gt; wrote:
</tt><blockquote class="blockquote"><pre style="margin: 0em;">On 3/27/07, gary thompson &lt;garyt@xxxxxxxxxxxxxxx&gt; wrote:
&gt; On 3/26/07, Edward d'Auvergne &lt;edward@xxxxxxxxxxxxx&gt; wrote:
&gt; &gt; On 3/27/07, Gary S. Thompson &lt;garyt@xxxxxxxxxxxxxxx&gt; wrote:</pre><br>
<pre style="margin: 0em;">[snip]</pre><br>
<pre style="margin: 0em;">&gt; &gt; &gt; e.g.it would be nice to have
&gt; &gt; &gt;
&gt; &gt; &gt; for residue in  all residues:
&gt; &gt; &gt;     for model in models:
&gt; &gt; &gt;              do_stuff-(tm)
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; as opposed to
&gt; &gt; &gt;
&gt; &gt; &gt; for model in models: #currently at the user level
&gt; &gt; &gt;     for residue in  all residues:
&gt; &gt; &gt;              do_stuff-(tm)
&gt; &gt; &gt;
&gt; &gt; &gt; now that might need something of the form
&gt; &gt; &gt;
&gt; &gt; &gt;         # Set the run names (also the names of preset model-free 
models).
&gt; &gt; &gt;         if local_tm:
&gt; &gt; &gt;             self.runs = ['tm0', 'tm1', 'tm2', 'tm3', 'tm4', 'tm5',
&gt; &gt; &gt; 'tm6', 'tm7', 'tm8', 'tm9']
&gt; &gt; &gt;         else:
&gt; &gt; &gt;             self.runs = ['m0', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7',
&gt; &gt; &gt; 'm8', 'm9']
&gt; &gt; &gt;
&gt; &gt; &gt; run.create_composite('super')
&gt; &gt; &gt; for name in self.runs:
&gt; &gt; &gt;
&gt; &gt; &gt;     run.create(name, 'mf')
&gt; &gt; &gt;     composite_add('super',name)
&gt; &gt; &gt;     minimise('newton', run='super')
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; which would minimise all runs in parallel...
&gt; &gt; &gt;
&gt; &gt; &gt; and I understand from chris that we are planning to do
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt;        # Set the run names (also the names of preset model-free models).
&gt; &gt; &gt;         if local_tm:
&gt; &gt; &gt;             self.runs = ['tm0', 'tm1', 'tm2', 'tm3', 'tm4', 'tm5',
&gt; &gt; &gt; 'tm6', 'tm7', 'tm8', 'tm9']
&gt; &gt; &gt;         else:
&gt; &gt; &gt;             self.runs = ['m0', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7',
&gt; &gt; &gt; 'm8', 'm9']
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt;      minimise('newton', runs=self.runs)
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; which would also work
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; now comes the tricky bit
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; all the minimisations etc would now become rfnctions to setup
&gt; &gt; &gt; minimsations and say submit them to a queue with a suitable object to
&gt; &gt; &gt; allow the results to be sorted out later.
&gt; &gt; &gt;
&gt; &gt; &gt; then at the end of minimise('newton', runs=self.runs) you would collect
&gt; &gt; &gt; in all the results from all calculations and complete the calculation so
&gt; &gt; &gt; we have something like
&gt; &gt; &gt;
&gt; &gt; &gt; for residue
&gt; &gt; &gt;     for run in runs:
&gt; &gt; &gt;        calculation-instance = setup-calculation(residue,run)
&gt; &gt; &gt;        queue.submit(calculation-instance)
&gt; &gt; &gt; while(queue.not_complete()):
&gt; &gt; &gt;     result.queue.get_result()
&gt; &gt; &gt;     result.record(self.reax.data)
&gt; &gt; &gt;
&gt; &gt; &gt; This will allow the maximum numer of calculations to be conducted in
&gt; &gt; &gt; parallel and will intrisically load balance as well as we can get
&gt; &gt;
&gt; &gt; There are a number of very important issues with this approach.  The
&gt; &gt; most important is that the loop over the data pipes corresponding to
&gt; &gt; the model-free models (the 'runs') is deliberately not part of the
&gt; &gt; relax codebase.  In Chris' implementation of the 'runs' argument
&gt; &gt; (which will need to be renamed) the loop will be at the highest level
&gt; &gt; of the code so that for the generic_fns.minimise code onwards nothing
&gt; &gt; changes.  This high level loop would probably be a very difficult
&gt; &gt; target for MPI as the whole relax data storage object will need to be
&gt; &gt; sent between nodes.  This multi-megabyte transfer per node, per
&gt; &gt; calculation is not ideal.
&gt; &gt;
&gt; no you wouldn't have to if put the whole thing over the wire as long
&gt; as you add calculations to do to a queue at the low level and then
&gt; requested the calculations  be completed at the end  of the high level
&gt; function. In the end of it the user and program see no difference its
&gt; a bit like how an optimising compiler works I guess....</pre><br>
<pre style="margin: 0em;">I'm not talking about your suggested implementation but Chris'
implementation (the runs argument) which we have already decided upon.
 Your suggestion affects this decision (as well as the whole relax UI,
I'll get to this later).</pre><br>
<pre style="margin: 0em;"><br>&gt; &gt; Secondly, and very importantly, relax doesn't loop over residues in
&gt; &gt; the model-free minimise() function.  relax loops over minimisation
&gt; &gt; instances.  For the 'mf' and 'local_tm' parameter sets, this is a loop
&gt; &gt; over the spin systems (i.e. molecules first, residues second, and spin
&gt; &gt; systems last).  For the 'diff' and 'all' parameters sets the number of
&gt; &gt; minimisation instances is one and hence the loop runs once and then
&gt; &gt; that's it.  Looping over these followed by looping over the data pipes
&gt; &gt; (ex-runs) is insane!  That is essentially first looping over the
&gt; &gt; finest grained level followed by the coarsest.
&gt;
&gt; I do not quite follow where the insanity comes from ;-)
&gt;
&gt; It is not problem...  What is required is to pass as few chunks of
&gt; data with the largest size and best balance of computations over the
&gt; wire...  Essentially  I want to (effectively, not literally) build a
&gt; list of residues and divide the residues out roughly by processor and
&gt; then find all the models required for each residue set them up the
&gt; whole set of calculations chunk the whole list by the number of
&gt; processors say *3 and then put all these calculations on a queue then
&gt; collect the results and put the results where they need to be.
&gt; Basically i am saying that in many cases minimisation instances and
&gt; runs are disjoint sets and so can be calculated at the same time e.g.
&gt; the result of residue3 run tm0 does not affect the result of residue 3
&gt; tm1 etc ....</pre><br>
<pre style="margin: 0em;">The insanity is from the fact that the suggestion of the looping over
residues first and then looping over the data pipes breaks the most
fundamental premise of the relax UI (user interface) design - the data
pipes and how the user interacts with them.  I cannot stress how bad
this is!</pre><br>
</blockquote><pre style="margin: 0em;"><br>Actually on further reflection as long as low level and high level
command cooperate very slightly I think it doesn't make a lot of
difference which runs as the outer loop. The main component of what I
am suggesting is that the pipes and everything remain the same but we
effectively use them as a means of scheduling (please feel free to
shoot this down as well ;-))</pre><br>
<pre style="margin: 0em;">so basically as long as you have a function of the form</pre><br>
<pre style="margin: 0em;">runs =[mf1,mf2...]</pre><br>
<pre style="margin: 0em;">minimise('newton',runs)</pre><br>
<pre style="margin: 0em;">it can all work with almost no architecture change</pre><br>
<pre style="margin: 0em;"><br>all you do is have model_free.minimise doing what it is doing in the
multi branch and adding commands to the multiprocessor queue along
with the attached commands to store the data back to the right place
in the relax data structures when each command has completed
processing.</pre><br>
<pre style="margin: 0em;">if you then loop over all pipes in   minimise('newton',runs) and do
all submission and then ask for the processing to occur at the end of
minimise('newton',runs) everything occurs in the right place and with
out inconvenient overlaps etc Now if processor queue wants to reorder
the queue thats its problem, because we know that everything that goes
to minimise is compatible i.e all the calculations are disjoint and no
one call withing minimise can affect the other</pre><br>
<pre style="margin: 0em;">please do go ahead and shoot me if needed I don't wish to cause havoc
just to understand what the best way to go is</pre><br>
<pre style="margin: 0em;">regards
gary</pre><br>
<br>

<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
</div><!-- end msgdata -->
<br />
<h3><a name="related" href="#related">Related Messages</a></h3>
<div class="relateddata">
<ul><li><strong>Follow-Ups</strong>:
<ul>
<li><strong><a name="00145" href="msg00145.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
</ul></li></ul>
<!--X-Follow-Ups-End-->
<!--X-References-->
<ul><li><strong>References</strong>:
<ul>
<li><strong><a name="00092" href="msg00092.html">relax and Grid computing.</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00112" href="msg00112.html">Re: relax, MPI, and Grid computing.</a></strong>
<ul><li><em>From:</em> Gary S. Thompson</li></ul></li>
<li><strong><a name="00114" href="msg00114.html">Re: relax, MPI, and Grid computing.</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00124" href="msg00124.html">how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Gary S. Thompson</li></ul></li>
<li><strong><a name="00126" href="msg00126.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00128" href="msg00128.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Gary S. Thompson</li></ul></li>
<li><strong><a name="00129" href="msg00129.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00131" href="msg00131.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> gary thompson</li></ul></li>
<li><strong><a name="00133" href="msg00133.html">Fwd: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> gary thompson</li></ul></li>
<li><strong><a name="00139" href="msg00139.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
</ul></li></ul>
<!--X-References-End-->
<!--X-BotPNI-->
</div><!-- end relateddata -->
<!-- NoBotLinksApartFromRelatedMessages -->

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->
<div class="footer">You are on the <a href="http://gna.org">Gna!</a> mail server.</div><br />
<div class="right">Powered by <a href="http://www.mhonarc.org">MHonArc</a>, Updated Wed Mar 28 03:01:50 2007</div>  
</body>
</html>
