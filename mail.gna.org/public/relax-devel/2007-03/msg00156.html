<!-- MHonArc v2.6.10 -->
<!--X-Subject: Re: r3243 &#45; in /branches/multi_processor: ./ multi/ prompt/	specific_fns/ -->
<!--X-From-R13: "Unel E. Fubzcfba" <tnelgNozo.yrrqf.np.hx> -->
<!--X-Date: Thu, 29 Mar 2007 18:43:51 +0200 -->
<!--X-Message-Id: 460BE559.7010901@bmb.leeds.ac.uk -->
<!--X-Content-Type: text/plain -->
<!--X-Reference: E1HWrC8&#45;0002Jl&#45;Ii@subversion.gna.org -->
<!--X-Reference: 460B9BA0.1060402@bmb.leeds.ac.uk -->
<!--X-Reference: 7f080ed10703290839g1afb16c7k476b60bca781dca4@mail.gmail.com -->
<!--X-Head-End-->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>Re: r3243 - in /branches/multi_processor: ./ multi/ prompt/	specific_fns/ -- March 29, 2007 - 18:43</title>
<link rel="stylesheet" type="text/css" href="/mail.gna.org/archives-color-gna.css"> 
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>
<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->
<h2><img src="/mail.gna.org/images/mail.orig.png" width="48" height="48"
alt="mail" class="pageicon" />Re: r3243 - in /branches/multi_processor: ./ multi/ prompt/	specific_fns/</h2>
<br />
<div class="topmenu">
<a href="../" class="tabs">Others Months</a> | <a href="index.html#00156" class="tabs">Index by Date</a> | <a href="threads.html#00156" class="tabs">Thread Index</a><br />
<span class="smaller">&gt;&gt;&nbsp;&nbsp;
[<a href="msg00155.html">Date Prev</a>] [<a href="msg00157.html">Date Next</a>] [<a href="msg00153.html">Thread Prev</a>] [<a href="msg00157.html">Thread Next</a>]
</div>

<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->
<h3><a name="header" href="#header">Header</a></h3>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->
<ul class="headdata">
<li class="menuitem">
<em>To</em>: Edward d'Auvergne &lt;edward.dauvergne@xxxxxxxxx&gt;</li>
<li class="menuitem">
<em>Date</em>: Thu, 29 Mar 2007 17:12:09 +0100</li>
<li class="menuitem">
<em>Cc</em>: relax-devel@xxxxxxx</li>
<li class="menuitem">
<em>Message-id</em>: &lt;<a href="msg00156.html">460BE559.7010901@bmb.leeds.ac.uk</a>&gt;</li>
<li class="menuitem">
<em>References</em>: &lt;E1HWrC8-0002Jl-Ii@subversion.gna.org&gt;	&lt;<a href="msg00148.html">460B9BA0.1060402@bmb.leeds.ac.uk</a>&gt;	&lt;<a href="msg00153.html">7f080ed10703290839g1afb16c7k476b60bca781dca4@mail.gmail.com</a>&gt;</li>
<li class="menuitem">
<em>User-agent</em>: Mozilla Thunderbird 1.0 (X11/20041206)</li>
</ul>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
</div><!-- end headdata -->
<br />
<h3><a name="content" href="#content">Content</a></h3>
<div class="postedby">Posted by <strong>Gary S. Thompson</strong> on March 29, 2007 - 18:43:</div>
<div class="msgdata">
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<pre style="margin: 0em;">Edward d'Auvergne wrote:</pre><br>
<blockquote class="blockquote"><pre style="margin: 0em;">On 3/29/07, Gary S. Thompson &lt;garyt@xxxxxxxxxxxxxxx&gt; wrote:</pre><br>
<blockquote class="blockquote"><tt>garyt@xxxxxxxxxxxxxxx wrote:<br>
&gt; Author: varioustoxins<br>
&gt; Date: Thu Mar 29 11:45:22 2007<br>
&gt; New Revision: 3243<br>
&gt;<br>
&gt; URL: <a  href="http://svn.gna.org/viewcvs/relax?rev=3243&amp;view=rev">http://svn.gna.org/viewcvs/relax?rev=3243&amp;view=rev</a><br>
&gt; Log:<br>
&gt; First fully working multi branch with both uniprocessor and mpi4py 
support<br>
&gt; communication overhead for 18 residues (test_short.py from chris) with<br>
&gt; in memory io ~25%<br>
&gt;<br>
Modified:<br>
    branches/multi_processor/multi/mpi4py_processor.py<br>
    branches/multi_processor/multi/uni_processor.py<br>
    branches/multi_processor/prompt/interpreter.py<br>
    branches/multi_processor/relax<br>
    branches/multi_processor/specific_fns/model_free.py</tt><br>
<br>
<pre style="margin: 0em;">as alluded to in the commit message with a fairly simple implimentation
(each minimisation instance is sent off separately) I see an overhead of
~25% with  with a small data set of 18 residues. I don't think this will
improve with the current implimentation as there are too many messages,
however, I  do intend to  increase the chunk size of  the communication
(multiple minimises per message) as one of the next steps and see what
the results are.
</pre></blockquote><pre style="margin: 0em;"><br></pre><br>
<pre style="margin: 0em;">That should decrease the communication overhead.  How did you
determine the percentage overhead value?
</pre></blockquote><pre style="margin: 0em;"><br></pre><br>
<tt>The run was made under mpi  and with the uniprocessor version on a 
single processor, so these are very crude overheads . Compaisons were 
made by comparing mpi runtime and non mpi runtime by wall</tt><br>
<br>
<blockquote class="blockquote"><pre style="margin: 0em;">And which model-free model
was/were optimised?</pre><br>
</blockquote><pre style="margin: 0em;"><br>worst case scenario!</pre><br>
<pre style="margin: 0em;">test_small.py:</pre><br>
<pre style="margin: 0em;">-----------------------------8&lt;----------------------------------------------:
# Script for model-free analysis.</pre><br>
<pre style="margin: 0em;">dataPaths = ['test_data/noe750.dat',
            'test_data/T1_750_hgts.bs',
            'test_data/T2_750_hgts.bs']</pre><br>
<pre style="margin: 0em;">dataTypes = [('NOE', '750', 750.8e6),
            ('R1', '750', 750.8e6),
            ('R2', '750', 750.8e6)]</pre><br>
<pre style="margin: 0em;"># Set the run names (also the names of preset model-free models).
#runs = ['tm1', 'tm2', 'tm3', 'tm4', 'tm5', 'tm6', 'tm7', 'tm8', 'tm9']
runs = ['m1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9']</pre><br>
<pre style="margin: 0em;"># Nuclei type
nuclei('N')</pre><br>
<pre style="margin: 0em;"># Loop over the runs.
for name in runs:
   # Create the run.
   run.create(name, 'mf')</pre><br>
<pre style="margin: 0em;">   # Load the sequence.
   #sequence.read(name, 'noe.500.out')</pre><br>
<pre style="margin: 0em;">   # Load a PDB file.
   structure.read_pdb(name, 'test_data/test.pdb')
   #pdb.read(name, 'test_data/test.pdb')
   structure.vectors(name, proton='HN')</pre><br>
<tt>   # Load the relaxation data.<br>
   for dataSet in xrange(len(dataPaths)):<br>
       relax_data.read(name, dataTypes[dataSet][0], 
dataTypes[dataSet][1], dataTypes[dataSet][2], dataPaths[dataSet])</tt><br>
<br>
<tt>   # Setup other values.<br>
   diffusion_tensor.init(name, 1e-8, fixed=1)<br>
   #diffusion_tensor.init(name, (1e-8, 1.0, 60, 290), param_types=0, 
spheroid_type='oblate', fixed=0)<br>
   value.set(name, 1.02 * 1e-10, 'bond_length')<br>
   value.set(name, -160 * 1e-6, 'csa')<br>
   #value.set(name, 0.970, 's2')<br>
   #value.set(name, 1.0, 's2f')<br>
   #value.set(name, 2048e-12, 'te')<br>
   #value.set(name, 2048e-12, 'tf')<br>
   #value.set(name, 2048e-12, 'ts')<br>
   #value.set(name, 0.149/(2*pi*600e6)**2, 'rex')</tt><br>
<br>
<pre style="margin: 0em;">   # Select the model-free model.
   model_free.select_model(run=name, model=name)
   #fix(name, 'all_res')</pre><br>
<pre style="margin: 0em;">   # Minimise.
   grid_search(name, inc=11)
   minimise('newton', run=name)</pre><br>
<pre style="margin: 0em;">   # Write the results.
   results.write(run=name, file='results', force=1)</pre><br>
<pre style="margin: 0em;"># Save the program state.
state.save('save', force=1)</pre><br>
<pre style="margin: 0em;">-----------------------------8&lt;----------------------------------------------:</pre><br>
<blockquote class="blockquote"><br>
<blockquote class="blockquote"><pre style="margin: 0em;">One other comment is that I have had to alter  prompt/interpreter.py
because it was exiting too early</pre><br>
<pre style="margin: 0em;"><br></pre><br>
<pre style="margin: 0em;">     # Quit.
-    if quit:
-        sys.exit()
+    # FIXME: need to drop off end of interpreter loop to exit cleanly
+    #if quit:
+    #    sys.exit()</pre><br>
<tt>I can't see a problem with it returning rather than quitting but 
obviously am ope to counter claims
</tt></blockquote><pre style="margin: 0em;"><br></pre><br>
<pre style="margin: 0em;">I really cannot for the life of me remember why I put that exit
statement there (that was so long ago).  Oh well, debugging should
pick up any problems.
</pre></blockquote><pre style="margin: 0em;"><br></pre><br>
<pre style="margin: 0em;">I haven't seen any as yet but the test suite will help</pre><br>
<blockquote class="blockquote"><pre style="margin: 0em;">On the topic of debugging, if you would like to
port the unit test code from the 1.3 line into your branch so you can
write unit tests for the code, the svnmerge program/script distributed
with Subversion will help a lot.</pre><br>
</blockquote><tt>yes thats on the list as well though some of the multiprocessor code 
will be hard to unit test</tt><br>
<br>
<blockquote class="blockquote"><br>
<blockquote class="blockquote"><tt>Overall I am very happy with the current results and feel that the 
level of change to the main relax code base is very small and that 
the code is relativley portable and well defined
</tt></blockquote><pre style="margin: 0em;"><br></pre><br>
<tt>That did touch very little of the model-free specific code base.  
</tt></blockquote><pre style="margin: 0em;"><br></pre><br>
<pre style="margin: 0em;">;-)</pre><br>
<blockquote class="blockquote"><pre style="margin: 0em;">One
question I have is will there be a separate model-free minimise()
function for normal and MPI operation?
</pre></blockquote><pre style="margin: 0em;"><br></pre><br>
<tt>no the non mpi version just calls the uniprocessor processor 
multi.uni_processor.  The current uniprocessor implimentation is non 
optimal by space on single processor machines but will have the same 
overhead by time as any other implimentations (barring the use of 
command cacheing which may save to object creation overhead)</tt><br>
<br>
<blockquote class="blockquote"><pre style="margin: 0em;">Another point is that I can't
run the code in the branch without having MPI up and running.</pre><br>
<br>
</blockquote><tt>you should be able to run relax without a --multi command line and 
without an mpirun and the uniprocessor implimentations should run. 
However, currently when I run it I get The dependency 'mpi4py' has not 
been installed is that the problem you have?? I will investigate the problem</tt><br>
<br>
<br>
<blockquote class="blockquote"><blockquote class="blockquote"><tt>obviously there is consdiderable code cleanup and documentation still 
to be done and also implimentation of processors for threading and 
ssh tunnels
</tt></blockquote><pre style="margin: 0em;"><br></pre><br>
<pre style="margin: 0em;">The code is shaping up nicely.  With a good clean up it should be
relatively easy to port to the 1.3 line later on.
</pre></blockquote><pre style="margin: 0em;"><br>yep time to go from alpha to beta, glad you like it</pre><br>
<blockquote class="blockquote"><pre style="margin: 0em;">1It looks like a
great framework for the threading and grid computing via ssh tunnels.</pre><br>
</blockquote><pre style="margin: 0em;">indeed thats the intention and design goal ;-)</pre><br>
<blockquote class="blockquote"><pre style="margin: 0em;">Cheers,</pre><br>
<pre style="margin: 0em;">Edward</pre><br>
</blockquote><pre style="margin: 0em;"><br>regards
gary</pre><br>
<blockquote class="blockquote"><pre style="margin: 0em;">_______________________________________________
relax (<a  href="http://nmr-relax.com">http://nmr-relax.com</a>)</pre><br>
<pre style="margin: 0em;">This is the relax-devel mailing list
relax-devel@xxxxxxx</pre><br>
<pre style="margin: 0em;">To unsubscribe from this list, get a password
reminder, or change your subscription options,
visit the list information page at
<a  href="https://mail.gna.org/listinfo/relax-devel">https://mail.gna.org/listinfo/relax-devel</a></pre><br>
<pre style="margin: 0em;">.</pre><br>
</blockquote><pre style="margin: 0em;"><br></pre><br>
<pre style="margin: 0em;">--
-------------------------------------------------------------------
Dr Gary Thompson
Astbury Centre for Structural Molecular Biology,
University of Leeds, Astbury Building,
Leeds, LS2 9JT, West-Yorkshire, UK             Tel. +44-113-3433024
email: garyt@xxxxxxxxxxxxxxx                   Fax  +44-113-2331407
-------------------------------------------------------------------</pre><br>
<pre style="margin: 0em;"><br></pre><br>
<br>

<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
</div><!-- end msgdata -->
<br />
<h3><a name="related" href="#related">Related Messages</a></h3>
<div class="relateddata">
<ul><li><strong>Follow-Ups</strong>:
<ul>
<li><strong><a name="00157" href="msg00157.html">Re: r3243 - in /branches/multi_processor: ./ multi/ prompt/	specific_fns/</a></strong>
<ul><li><em>From:</em> gary thompson</li></ul></li>
</ul></li></ul>
<!--X-Follow-Ups-End-->
<!--X-References-->
<ul><li><strong>References</strong>:
<ul>
<li><strong><a name="00148" href="msg00148.html">Re: r3243 - in /branches/multi_processor: ./ multi/ prompt/	specific_fns/</a></strong>
<ul><li><em>From:</em> Gary S. Thompson</li></ul></li>
<li><strong><a name="00153" href="msg00153.html">Re: r3243 - in /branches/multi_processor: ./ multi/ prompt/	specific_fns/</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
</ul></li></ul>
<!--X-References-End-->
<!--X-BotPNI-->
</div><!-- end relateddata -->
<!-- NoBotLinksApartFromRelatedMessages -->

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->
<div class="footer"></div><br />
<div class="right">Powered by <a href="http://www.mhonarc.org">MHonArc</a>, Updated Thu Mar 29 19:41:03 2007</div>  
</body>
</html>
