<!-- MHonArc v2.6.10 -->
<!--X-Subject: Re: how to parallelise model_free minimise -->
<!--X-From-R13: "tnel gubzcfba" <tnelg.naq.fnenuoNtznvy.pbz> -->
<!--X-Date: Wed, 28 Mar 2007 11:41:22 +0200 -->
<!--X-Message-Id: f001463a0703280240g6866c37bgdf09d027df3d34bc@mail.gmail.com -->
<!--X-Content-Type: text/plain -->
<!--X-Reference: 7f080ed10703191030h79036e06w56912aa1d9130f48@mail.gmail.com -->
<!--X-Reference: 4603EA08.60801@bmb.leeds.ac.uk -->
<!--X-Reference: 7f080ed10703252217x7db43e6bxfe7324ad0379c778@mail.gmail.com -->
<!--X-Reference: 4607F0AB.6000807@bmb.leeds.ac.uk -->
<!--X-Reference: 7f080ed10703261002i7cc384a6n8bf20be7aaad4e0e@mail.gmail.com -->
<!--X-Reference: f001463a0703270015n76d1b728m749f70fba54d8213@mail.gmail.com -->
<!--X-Reference: f001463a0703270022iec6830fs2aec68f942d16cb2@mail.gmail.com -->
<!--X-Reference: 7f080ed10703270907h3e882251v6b66b329ecfeb910@mail.gmail.com -->
<!--X-Reference: f001463a0703271218n67b2f3a3oe5aff06a4810d178@mail.gmail.com -->
<!--X-Reference: 7f080ed10703271746n2c675b79ib07e7c7c13f99671@mail.gmail.com -->
<!--X-Head-End-->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>Re: how to parallelise model_free minimise -- March 28, 2007 - 11:41</title>
<link rel="stylesheet" type="text/css" href="/mail.gna.org/archives-color-gna.css"> 
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>
<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->
<h2><img src="/mail.gna.org/images/mail.orig.png" width="48" height="48"
alt="mail" class="pageicon" />Re: how to parallelise model_free minimise</h2>
<br />
<div class="topmenu">
<a href="../" class="tabs">Others Months</a> | <a href="index.html#00146" class="tabs">Index by Date</a> | <a href="threads.html#00146" class="tabs">Thread Index</a><br />
<span class="smaller">&gt;&gt;&nbsp;&nbsp;
[<a href="msg00145.html">Date Prev</a>] [<a href="msg00147.html">Date Next</a>] [<a href="msg00145.html">Thread Prev</a>] [<a href="msg00150.html">Thread Next</a>]
</div>

<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->
<h3><a name="header" href="#header">Header</a></h3>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->
<ul class="headdata">
<li class="menuitem">
<em>To</em>: &quot;Edward d'Auvergne&quot; &lt;edward.dauvergne@xxxxxxxxx&gt;</li>
<li class="menuitem">
<em>Date</em>: Wed, 28 Mar 2007 10:40:19 +0100</li>
<li class="menuitem">
<em>Cc</em>: relax-devel@xxxxxxx</li>
<li class="menuitem">
<em>Dkim-signature</em>: a=rsa-sha1; c=relaxed/relaxed; d=gmail.com; s=beta;	h=domainkey-signature:received:received:message-id:date:from:to:subject:cc:in-reply-to:mime-version:content-type:content-transfer-encoding:content-disposition:references;	b=H+LrCxpf7wEDQUcEZySzg3TT3oOQz/6XHvHyL/+ASmbNf05SldYLOJTQLHOmvdPQS9m8eGrcobFmlxTOMuS0fVPJIDR3AfFOdBU+z/O7/naSom/vw3mx3CpRI00Nk7u/awh3nxwmcIiNnm2SmIO/lkFvbSChB5RXzs5IEwUZtog=</li>
<li class="menuitem">
<em>Message-id</em>: &lt;<a href="msg00146.html">f001463a0703280240g6866c37bgdf09d027df3d34bc@mail.gmail.com</a>&gt;</li>
<li class="menuitem">
<em>References</em>: &lt;<a href="msg00092.html">7f080ed10703191030h79036e06w56912aa1d9130f48@mail.gmail.com</a>&gt;	&lt;<a href="msg00124.html">4603EA08.60801@bmb.leeds.ac.uk</a>&gt;	&lt;<a href="msg00126.html">7f080ed10703252217x7db43e6bxfe7324ad0379c778@mail.gmail.com</a>&gt;	&lt;<a href="msg00128.html">4607F0AB.6000807@bmb.leeds.ac.uk</a>&gt;	&lt;<a href="msg00129.html">7f080ed10703261002i7cc384a6n8bf20be7aaad4e0e@mail.gmail.com</a>&gt;	&lt;<a href="msg00131.html">f001463a0703270015n76d1b728m749f70fba54d8213@mail.gmail.com</a>&gt;	&lt;<a href="msg00133.html">f001463a0703270022iec6830fs2aec68f942d16cb2@mail.gmail.com</a>&gt;	&lt;<a href="msg00139.html">7f080ed10703270907h3e882251v6b66b329ecfeb910@mail.gmail.com</a>&gt;	&lt;<a href="msg00144.html">f001463a0703271218n67b2f3a3oe5aff06a4810d178@mail.gmail.com</a>&gt;	&lt;<a href="msg00145.html">7f080ed10703271746n2c675b79ib07e7c7c13f99671@mail.gmail.com</a>&gt;</li>
</ul>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
</div><!-- end headdata -->
<br />
<h3><a name="content" href="#content">Content</a></h3>
<div class="postedby">Posted by <strong>gary thompson</strong> on March 28, 2007 - 11:41:</div>
<div class="msgdata">
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<tt>On 3/28/07, Edward d'Auvergne &lt;edward.dauvergne@xxxxxxxxx&gt; wrote:
</tt><blockquote class="blockquote"><pre style="margin: 0em;">A major problem with the looping over data pipes within the model-free
minimise() function is that you won't have access to the 'pipes'
argument.
</pre></blockquote><pre style="margin: 0em;"><br>Ok I am quite happy to sit back and let this hang for the moment ;-)
The whole things is literally quite trivial to implement (5 lines of
code maybe less and I don't think I can reoganise the relax ui and
data structure with that amount of code)
so I will leave it to when the redesign is finished and see where we
are and whether it will work with what we have.</pre><br>
<pre style="margin: 0em;">However, the whole point here is that i don't need any access to the
runs argument or the pipes to make this work you need access to the
relax.processor from the user level *(and possibly not even that) and
from the model_free.minimise loop nowhere else it doesn't require
major ui or code base reorganisations</pre><br>
<pre style="margin: 0em;">regards
gary</pre><br>
<tt><br>The UI design for the 1.3 line and above is such that the
</tt><blockquote class="blockquote"><pre style="margin: 0em;">'run' user function argument used in the 1.2 line no longer exists.
This value will no longer be propagated throughout the program, and
the same goes with the new 'pipes' argument.  Instead we now have the
concept of the current data pipe.  Chris' idea of the runs argument is
that we catch this argument at the level of the user function and
simply change the current data pipe and execute the user function
successively on the given data pipes.  This code is not part of the
user function itself and none of the relax code base is touched
(excluding the 'prompt' directory).  See the pipe_loop() function in
the relax redesign document 'docs/data_model_redesign' in the current
1.3 line for more details (point 3).  That document also has links to
the mailing list discussions.</pre><br>
<pre style="margin: 0em;">Please consider dropping the idea of the looping over data pipes as
part of the model-free minimise_mpi() function (or what ever the new
function(s) will be called).  The concept significantly clashes with
the relax UI design - a design which cannot be changed without an in
depth analysis of the impact on the user functions and serious thought
and analysis on the impact to the user experience.  And the benefit of
looping over the data pipes for parallelisation is questionable (I
cannot think of any communicational or computational benefits unless,
of course, that was the only part which was to be parallelised, which
it isn't).</pre><br>
<pre style="margin: 0em;">Cheers,</pre><br>
<pre style="margin: 0em;">Edward</pre><br>
<pre style="margin: 0em;"><br>On 3/28/07, gary thompson &lt;garyt.and.sarahb@xxxxxxxxx&gt; wrote:
&gt; On 3/27/07, Edward d'Auvergne &lt;edward.dauvergne@xxxxxxxxx&gt; wrote:
&gt; &gt; On 3/27/07, gary thompson &lt;garyt@xxxxxxxxxxxxxxx&gt; wrote:
&gt; &gt; &gt; On 3/26/07, Edward d'Auvergne &lt;edward@xxxxxxxxxxxxx&gt; wrote:
&gt; &gt; &gt; &gt; On 3/27/07, Gary S. Thompson &lt;garyt@xxxxxxxxxxxxxxx&gt; wrote:
&gt; &gt;
&gt; &gt; [snip]
&gt; &gt;
&gt; &gt; &gt; &gt; &gt; e.g.it would be nice to have
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; for residue in  all residues:
&gt; &gt; &gt; &gt; &gt;     for model in models:
&gt; &gt; &gt; &gt; &gt;              do_stuff-(tm)
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; as opposed to
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; for model in models: #currently at the user level
&gt; &gt; &gt; &gt; &gt;     for residue in  all residues:
&gt; &gt; &gt; &gt; &gt;              do_stuff-(tm)
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; now that might need something of the form
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;         # Set the run names (also the names of preset model-free 
models).
&gt; &gt; &gt; &gt; &gt;         if local_tm:
&gt; &gt; &gt; &gt; &gt;             self.runs = ['tm0', 'tm1', 'tm2', 'tm3', 'tm4', 'tm5',
&gt; &gt; &gt; &gt; &gt; 'tm6', 'tm7', 'tm8', 'tm9']
&gt; &gt; &gt; &gt; &gt;         else:
&gt; &gt; &gt; &gt; &gt;             self.runs = ['m0', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 
'm7',
&gt; &gt; &gt; &gt; &gt; 'm8', 'm9']
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; run.create_composite('super')
&gt; &gt; &gt; &gt; &gt; for name in self.runs:
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;     run.create(name, 'mf')
&gt; &gt; &gt; &gt; &gt;     composite_add('super',name)
&gt; &gt; &gt; &gt; &gt;     minimise('newton', run='super')
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; which would minimise all runs in parallel...
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; and I understand from chris that we are planning to do
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;        # Set the run names (also the names of preset model-free 
models).
&gt; &gt; &gt; &gt; &gt;         if local_tm:
&gt; &gt; &gt; &gt; &gt;             self.runs = ['tm0', 'tm1', 'tm2', 'tm3', 'tm4', 'tm5',
&gt; &gt; &gt; &gt; &gt; 'tm6', 'tm7', 'tm8', 'tm9']
&gt; &gt; &gt; &gt; &gt;         else:
&gt; &gt; &gt; &gt; &gt;             self.runs = ['m0', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 
'm7',
&gt; &gt; &gt; &gt; &gt; 'm8', 'm9']
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;      minimise('newton', runs=self.runs)
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; which would also work
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; now comes the tricky bit
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; all the minimisations etc would now become rfnctions to setup
&gt; &gt; &gt; &gt; &gt; minimsations and say submit them to a queue with a suitable object 
to
&gt; &gt; &gt; &gt; &gt; allow the results to be sorted out later.
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; then at the end of minimise('newton', runs=self.runs) you would 
collect
&gt; &gt; &gt; &gt; &gt; in all the results from all calculations and complete the 
calculation so
&gt; &gt; &gt; &gt; &gt; we have something like
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; for residue
&gt; &gt; &gt; &gt; &gt;     for run in runs:
&gt; &gt; &gt; &gt; &gt;        calculation-instance = setup-calculation(residue,run)
&gt; &gt; &gt; &gt; &gt;        queue.submit(calculation-instance)
&gt; &gt; &gt; &gt; &gt; while(queue.not_complete()):
&gt; &gt; &gt; &gt; &gt;     result.queue.get_result()
&gt; &gt; &gt; &gt; &gt;     result.record(self.reax.data)
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; This will allow the maximum numer of calculations to be conducted in
&gt; &gt; &gt; &gt; &gt; parallel and will intrisically load balance as well as we can get
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; There are a number of very important issues with this approach.  The
&gt; &gt; &gt; &gt; most important is that the loop over the data pipes corresponding to
&gt; &gt; &gt; &gt; the model-free models (the 'runs') is deliberately not part of the
&gt; &gt; &gt; &gt; relax codebase.  In Chris' implementation of the 'runs' argument
&gt; &gt; &gt; &gt; (which will need to be renamed) the loop will be at the highest level
&gt; &gt; &gt; &gt; of the code so that for the generic_fns.minimise code onwards nothing
&gt; &gt; &gt; &gt; changes.  This high level loop would probably be a very difficult
&gt; &gt; &gt; &gt; target for MPI as the whole relax data storage object will need to be
&gt; &gt; &gt; &gt; sent between nodes.  This multi-megabyte transfer per node, per
&gt; &gt; &gt; &gt; calculation is not ideal.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; no you wouldn't have to if put the whole thing over the wire as long
&gt; &gt; &gt; as you add calculations to do to a queue at the low level and then
&gt; &gt; &gt; requested the calculations  be completed at the end  of the high level
&gt; &gt; &gt; function. In the end of it the user and program see no difference its
&gt; &gt; &gt; a bit like how an optimising compiler works I guess....
&gt; &gt;
&gt; &gt; I'm not talking about your suggested implementation but Chris'
&gt; &gt; implementation (the runs argument) which we have already decided upon.
&gt; &gt;  Your suggestion affects this decision (as well as the whole relax UI,
&gt; &gt; I'll get to this later).
&gt; &gt;
&gt; &gt;
&gt; &gt; &gt; &gt; Secondly, and very importantly, relax doesn't loop over residues in
&gt; &gt; &gt; &gt; the model-free minimise() function.  relax loops over minimisation
&gt; &gt; &gt; &gt; instances.  For the 'mf' and 'local_tm' parameter sets, this is a loop
&gt; &gt; &gt; &gt; over the spin systems (i.e. molecules first, residues second, and spin
&gt; &gt; &gt; &gt; systems last).  For the 'diff' and 'all' parameters sets the number of
&gt; &gt; &gt; &gt; minimisation instances is one and hence the loop runs once and then
&gt; &gt; &gt; &gt; that's it.  Looping over these followed by looping over the data pipes
&gt; &gt; &gt; &gt; (ex-runs) is insane!  That is essentially first looping over the
&gt; &gt; &gt; &gt; finest grained level followed by the coarsest.
&gt; &gt; &gt;
&gt; &gt; &gt; I do not quite follow where the insanity comes from ;-)
&gt; &gt; &gt;
&gt; &gt; &gt; It is not problem...  What is required is to pass as few chunks of
&gt; &gt; &gt; data with the largest size and best balance of computations over the
&gt; &gt; &gt; wire...  Essentially  I want to (effectively, not literally) build a
&gt; &gt; &gt; list of residues and divide the residues out roughly by processor and
&gt; &gt; &gt; then find all the models required for each residue set them up the
&gt; &gt; &gt; whole set of calculations chunk the whole list by the number of
&gt; &gt; &gt; processors say *3 and then put all these calculations on a queue then
&gt; &gt; &gt; collect the results and put the results where they need to be.
&gt; &gt; &gt; Basically i am saying that in many cases minimisation instances and
&gt; &gt; &gt; runs are disjoint sets and so can be calculated at the same time e.g.
&gt; &gt; &gt; the result of residue3 run tm0 does not affect the result of residue 3
&gt; &gt; &gt; tm1 etc ....
&gt; &gt;
&gt; &gt; The insanity is from the fact that the suggestion of the looping over
&gt; &gt; residues first and then looping over the data pipes breaks the most
&gt; &gt; fundamental premise of the relax UI (user interface) design - the data
&gt; &gt; pipes and how the user interacts with them.  I cannot stress how bad
&gt; &gt; this is!
&gt; &gt;
&gt;
&gt; Actually on further reflection as long as low level and high level
&gt; command cooperate very slightly I think it doesn't make a lot of
&gt; difference which runs as the outer loop. The main component of what I
&gt; am suggesting is that the pipes and everything remain the same but we
&gt; effectively use them as a means of scheduling (please feel free to
&gt; shoot this down as well ;-))
&gt;
&gt; so basically as long as you have a function of the form
&gt;
&gt; runs =[mf1,mf2...]
&gt;
&gt; minimise('newton',runs)
&gt;
&gt; it can all work with almost no architecture change
&gt;
&gt;
&gt; all you do is have model_free.minimise doing what it is doing in the
&gt; multi branch and adding commands to the multiprocessor queue along
&gt; with the attached commands to store the data back to the right place
&gt; in the relax data structures when each command has completed
&gt; processing.
&gt;
&gt; if you then loop over all pipes in   minimise('newton',runs) and do
&gt; all submission and then ask for the processing to occur at the end of
&gt; minimise('newton',runs) everything occurs in the right place and with
&gt; out inconvenient overlaps etc Now if processor queue wants to reorder
&gt; the queue thats its problem, because we know that everything that goes
&gt; to minimise is compatible i.e all the calculations are disjoint and no
&gt; one call withing minimise can affect the other
&gt;
&gt; please do go ahead and shoot me if needed I don't wish to cause havoc
&gt; just to understand what the best way to go is
&gt;
&gt; regards
&gt; gary
&gt;</pre><br>
</blockquote><pre style="margin: 0em;"><br></pre><br>

<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
</div><!-- end msgdata -->
<br />
<h3><a name="related" href="#related">Related Messages</a></h3>
<div class="relateddata">
<ul><li><strong>Follow-Ups</strong>:
<ul>
<li><strong><a name="00150" href="msg00150.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
</ul></li></ul>
<!--X-Follow-Ups-End-->
<!--X-References-->
<ul><li><strong>References</strong>:
<ul>
<li><strong><a name="00092" href="msg00092.html">relax and Grid computing.</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00124" href="msg00124.html">how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Gary S. Thompson</li></ul></li>
<li><strong><a name="00126" href="msg00126.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00128" href="msg00128.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Gary S. Thompson</li></ul></li>
<li><strong><a name="00129" href="msg00129.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00131" href="msg00131.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> gary thompson</li></ul></li>
<li><strong><a name="00133" href="msg00133.html">Fwd: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> gary thompson</li></ul></li>
<li><strong><a name="00139" href="msg00139.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
<li><strong><a name="00144" href="msg00144.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> gary thompson</li></ul></li>
<li><strong><a name="00145" href="msg00145.html">Re: how to parallelise model_free minimise</a></strong>
<ul><li><em>From:</em> Edward d'Auvergne</li></ul></li>
</ul></li></ul>
<!--X-References-End-->
<!--X-BotPNI-->
</div><!-- end relateddata -->
<!-- NoBotLinksApartFromRelatedMessages -->

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->
<div class="footer"></div><br />
<div class="right">Powered by <a href="http://www.mhonarc.org">MHonArc</a>, Updated Thu Mar 29 16:22:55 2007</div>  
</body>
</html>
