<!-- MHonArc v2.6.19+ -->
<!--X-Subject: Re: [bug #23618] queuing system for multi processors is not well designed. -->
<!--X-From-R13: "Sqjneq q'Ohiretar" &#60;rqjneqNaze&#45;erynk.pbz> -->
<!--X-Date: Mon, 08 Jun 2015 18:12:30 +0200 -->
<!--X-Message-Id: CAED9pY83HCy3Dtiggv&#45;MmhmcQGjwh==8Ba_OFQOSmAqY3MdepQ@mail.gmail.com -->
<!--X-Content-Type: text/plain -->
<!--X-Reference: 20150527&#45;001057.sv20529.76921@gna.org -->
<!--X-Reference: 20150527&#45;005714.sv20529.16205@gna.org -->
<!--X-Reference: 20150527&#45;010341.sv20529.51870@gna.org -->
<!--X-Reference: 20150527&#45;013551.sv20529.31555@gna.org -->
<!--X-Head-End-->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>Re: [bug #23618] queuing system for multi processors is not well designed. -- June 08, 2015 - 18:12</title>
<link rel="stylesheet" type="text/css" href="/mail.gna.org/archives-color-gna.css"> 
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>
<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->
<h2><img src="/mail.gna.org/images/mail.orig.png" width="48" height="48"
alt="mail" class="pageicon" />Re: [bug #23618] queuing system for multi processors is not well designed.</h2>
<br />
<div class="topmenu">
<a href="../" class="tabs">Others Months</a> | <a href="index.html#00008" class="tabs">Index by Date</a> | <a href="threads.html#00008" class="tabs">Thread Index</a><br />
<span class="smaller">&gt;&gt;&nbsp;&nbsp;
[<a href="msg00007.html">Date Prev</a>] [<a href="msg00009.html">Date Next</a>] [<a href="msg00005.html">Thread Prev</a>] [<a href="msg00014.html">Thread Next</a>]
</div>

<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->
<h3><a name="header" href="#header">Header</a></h3>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->
<ul class="headdata">
<li class="menuitem">
<em>Date</em>: Mon, 8 Jun 2015 18:11:59 +0200</li>
<li class="menuitem">
<em>Cc</em>: &quot;relax-devel@xxxxxxx&quot; &lt;relax-devel@xxxxxxx&gt;</li>
<li class="menuitem">
<em>Dkim-signature</em>: v=1; a=rsa-sha256; c=relaxed/relaxed; d=gmail.com; s=20120113; h=mime-version:sender:in-reply-to:references:date:message-id:subject :from:cc:content-type; bh=X2tScu3KVfQJuhRtP0/abxl+fak1z9/ooaBLt/PL2Eo=; b=ilF5eTf3/q6hJmlGKNKfiznyiUT6C7hZtY6dZaoMX0g5CUNjQw9Z0DMVRUGYHGOCad iy2QvtnYp0vUKgIknvLMsvui0YuriawJQoXQUBFBTbJbShxgrIxz6b6mdgcqOtnAAfYY J9Ek36hOnmhAE2xQJ3rBHWqOur+GhmGp4AIq47WTPZV0EADRzk88fHvfoqs9igHwVnwz 12wupJfmcljVKpuurZvH4NjBDOHhj38+GJVEchA4MkTD0pWhNR90vKsE2bh9BojXwJBl SuAmuhRhop2di4mubtSEmD/klNPB2iaYik24veQ2TQnf7yJEBzbtuoDI3pcruiU1/udC Y+oQ==</li>
<li class="menuitem">
<em>Message-id</em>: &lt;CAED9pY83HCy3Dtiggv-MmhmcQGjwh==8Ba_OFQOSmAqY3MdepQ@mail.gmail.com&gt;</li>
<li class="menuitem">
<em>References</em>: &lt;20150527-001057.sv20529.76921@gna.org&gt; &lt;20150527-005714.sv20529.16205@gna.org&gt; &lt;20150527-010341.sv20529.51870@gna.org&gt; &lt;20150527-013551.sv20529.31555@gna.org&gt;</li>
</ul>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
</div><!-- end headdata -->
<br />
<h3><a name="content" href="#content">Content</a></h3>
<div class="postedby">Posted by <strong>Edward d'Auvergne</strong> on June 08, 2015 - 18:12:</div>
<div class="msgdata">
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<pre style="margin: 0em;">On 27 May 2015 at 03:35, Troels E. Linnet
&lt;NO-REPLY.INVALID-ADDRESS@xxxxxxx&gt; wrote:
</pre><blockquote class="blockquote"><pre style="margin: 0em;">Follow-up Comment #5, bug #23618 (project relax):

It is weird, that when calculations is not submitted, slave processors shows
100 %, and the master does it all.

13578 tlinnet   20   0 1315m 386m  25m R 133.6  1.6   1:08.73 python

13584 tlinnet   20   0  784m  72m  21m R 100.2  0.3   1:03.22 python

13579 tlinnet   20   0  784m  72m  21m R 99.9  0.3   1:03.23 python

13580 tlinnet   20   0  784m  72m  21m R 99.9  0.3   1:03.25 python

13581 tlinnet   20   0  784m  73m  21m R 99.9  0.3   1:03.20 python

13582 tlinnet   20   0  784m  72m  21m R 99.9  0.3   1:03.22 python

13583 tlinnet   20   0  784m  72m  21m R 99.9  0.3   1:03.21 python

13585 tlinnet   20   0  784m  72m  21m R 99.9  0.3   1:03.21 python

13586 tlinnet   20   0  784m  72m  21m R 99.9  0.3   1:03.23 python

13587 tlinnet   20   0  784m  72m  21m R 99.9  0.3   1:03.24 python

13588 tlinnet   20   0  784m  72m  21m R 99.9  0.3   1:03.20 python

13589 tlinnet   20   0  784m  72m  21m R 99.9  0.3   1:03.20 python
</pre></blockquote><pre style="margin: 0em;">

Note that this is how by default OpenMPI operates.  The master and all
slaves are always run at 100%, even when they are idle.  They are
actually using 100% of the CPU to continually poll the queues.  The
OpenMPI people chose this behaviour to minimise data transfer
bottlenecks, and is based on the assumption that all of the
calculation time will be parallelised and that you will have full
access to the nodes you are allocated.


</pre><blockquote class="blockquote"><pre style="margin: 0em;">When jobs are submitted, they show 200 %

13579 tlinnet   20   0 1023m 150m  23m R 199.9  0.6   3:20.01 python

13580 tlinnet   20   0 1023m 152m  23m R 199.9  0.6   3:19.77 python

13582 tlinnet   20   0 1023m 152m  23m R 199.9  0.6   3:19.22 python

13583 tlinnet   20   0 1023m 149m  23m R 199.9  0.6   3:18.93 python

13584 tlinnet   20   0 1023m 151m  23m R 199.9  0.6   3:18.40 python

13585 tlinnet   20   0 1023m 149m  23m R 199.9  0.6   3:18.12 python

13586 tlinnet   20   0 1023m 149m  23m R 199.9  0.6   3:17.89 python

13588 tlinnet   20   0 1023m 151m  23m R 199.9  0.6   3:17.32 python

13589 tlinnet   20   0 1023m 151m  23m R 199.9  0.6   3:16.74 python

13587 tlinnet   20   0 1023m 151m  23m R 199.5  0.6   3:17.60 python

13581 tlinnet   20   0 1023m 150m  23m R 199.2  0.6   3:19.40 python

13578 tlinnet   20   0 1638m 636m  26m R 99.9  2.6   3:49.60 python
</pre></blockquote><pre style="margin: 0em;">

The 200% is a little strange, but OpenMPI CPU percentage numbers have
been strange on Linux for a long time now.  I've seen nodes at 200%,
and sometimes at 50%.  I don't know what this is about - if it is an
OpenMPI bug, a Linux kernel reporting bug, or if relax is doing
something strange (I doubt it's the last option, as a Google search
will show that others have encountered such strangeness).

Regards,

Edward


</pre>
<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
</div><!-- end msgdata -->
<br />
<h3><a name="related" href="#related">Related Messages</a></h3>
<div class="relateddata">
<!--X-Follow-Ups-End-->
<!--X-References-->
<!--X-References-End-->
<!--X-BotPNI-->
</div><!-- end relateddata -->
<!-- NoBotLinksApartFromRelatedMessages -->

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->
<div class="footer"></div><br />
<div class="right">Powered by <a href="http://www.mhonarc.org">MHonArc</a>, Updated Thu Jun 11 13:40:21 2015</div>  
</body>
</html>
