<!-- MHonArc v2.6.18 -->
<!--X-Subject: Re: How is the R2eff data collected and processed for clustered analysis? -->
<!--X-From-R13: "Sqjneq q'Ohiretar" &#60;rqjneqNaze&#45;erynk.pbz> -->
<!--X-Date: Wed, 04 Jun 2014 14:52:35 +0200 -->
<!--X-Message-Id: CAED9pY_cOhVQdqDAY8gq8=&#45;9r0tvx8AEM8BwBzr5AFNthfZu5A@mail.gmail.com -->
<!--X-Content-Type: text/plain -->
<!--X-Reference: CA+CBx2Mkmn7AyX1O=CVFbG68BSq9nEMBcZUUMnMBJ8vAAkSm1w@mail.gmail.com -->
<!--X-Head-End-->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>Re: How is the R2eff data collected and processed for clustered analysis? -- June 04, 2014 - 14:52</title>
<link rel="stylesheet" type="text/css" href="/mail.gna.org/archives-color-gna.css"> 
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>
<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->
<h2><img src="/mail.gna.org/images/mail.orig.png" width="48" height="48"
alt="mail" class="pageicon" />Re: How is the R2eff data collected and processed for clustered analysis?</h2>
<br />
<div class="topmenu">
<a href="../" class="tabs">Others Months</a> | <a href="index.html#00006" class="tabs">Index by Date</a> | <a href="threads.html#00006" class="tabs">Thread Index</a><br />
<span class="smaller">&gt;&gt;&nbsp;&nbsp;
[<a href="msg00005.html">Date Prev</a>] [<a href="msg00007.html">Date Next</a>] [<a href="msg00028.html">Thread Prev</a>] [<a href="msg00008.html">Thread Next</a>]
</div>

<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->
<h3><a name="header" href="#header">Header</a></h3>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->
<ul class="headdata">
<li class="menuitem">
<em>To</em>: Troels Emtekær Linnet &lt;tlinnet@xxxxxxxxxxxxx&gt;</li>
<li class="menuitem">
<em>Date</em>: Wed, 4 Jun 2014 14:52:04 +0200</li>
<li class="menuitem">
<em>Cc</em>: &quot;relax-devel@xxxxxxx&quot; &lt;relax-devel@xxxxxxx&gt;</li>
<li class="menuitem">
<em>Dkim-signature</em>: v=1; a=rsa-sha256; c=relaxed/relaxed; d=gmail.com; s=20120113; h=mime-version:sender:in-reply-to:references:date:message-id:subject :from:to:cc:content-type; bh=qd/kCyDzX1MD7vvA0h7i1hpR85pMwIdUYOHi/TpOdKw=; b=ojidggFl8Je4QxFAAwNPoLCw6jViDcYEFn6YYh3AzTAVrDutwwGLpOGE6No43+CtPd n6vymc8Werpy9u6jsM+Vig0O05BGwsuV8M4NIyGYQDatgZTe4uCUJR1ye3B8QQNunmEx z+kaJxNvx3ATfxjZmfO8XlMbvartFXjl0VTi2cOuysIDxOeb+a1DauZ0Bu341bU6M7Xo ntX2GQGCR5s7ueF9ldmXUqRkMOfL8ZH+J59LkGF6d56OpSu0gzOmGa1aR2lowYUYhV9a Zd5WQEXjQKX1QOw7SYI+a987KnySTf2BRTH/OlgouFcBxazv93KpDWZXHEaWe6lqi35x 2i6w==</li>
<li class="menuitem">
<em>Message-id</em>: &lt;CAED9pY_cOhVQdqDAY8gq8=-9r0tvx8AEM8BwBzr5AFNthfZu5A@mail.gmail.com&gt;</li>
<li class="menuitem">
<em>References</em>: &lt;CA+CBx2Mkmn7AyX1O=CVFbG68BSq9nEMBcZUUMnMBJ8vAAkSm1w@mail.gmail.com&gt;</li>
</ul>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
</div><!-- end headdata -->
<br />
<h3><a name="content" href="#content">Content</a></h3>
<div class="postedby">Posted by <strong>Edward d'Auvergne</strong> on June 04, 2014 - 14:52:</div>
<div class="msgdata">
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<pre style="margin: 0em;">Hi Troels,

Please see below:


</pre><blockquote class="blockquote"><pre style="margin: 0em;">After the changes to the lib/dispersion/model.py files, I see massive
speed-up of the computations.

During 2 days, I performed over 600 global fittings for a 68 residue
protein, where all residues where clustered.I just did it with 1 cpu.

This is really really impressive.

I did though also alter how the grid search was performed, pre-setting some
of the values from known values referred to in a paper.
So I can't really say what has cut the time down.
</pre></blockquote><pre style="margin: 0em;">

It looks like the dispersion analysis is faster, but probably by a
factor of between 1 to 2 for the different dispersion models.  So the
huge speed up will likely be due to the cuts in the computationally
expensive grid search.  That is why there are all those tricks in the
auto-analysis - copying parameters from other optimised models, either
nested or analytic to numeric, and averaging values for the cluster
analysis - which were published as part of the paper on this analysis
(<a  rel="nofollow" href="http://dx.doi.org/10.1093/bioinformatics/btu166">http://dx.doi.org/10.1093/bioinformatics/btu166</a>).


</pre><blockquote class="blockquote"><pre style="margin: 0em;">But looking at the calculations running, the minimisation runs quite fast.

So, how does relax do the collecting of data for global fitting?
</pre></blockquote><pre style="margin: 0em;">

You can see this in the docstring for the dispersion target function
class.   For example for the R2eff/R1rho values:

&quot;&quot;&quot;
        @keyword values:            The R2eff/R1rho values.  The
dimensions are {Ei, Si, Mi, Oi, Di}.
        @type values:               rank-4 list of numpy rank-1 float arrays
&quot;&quot;&quot;

So you can see that the second dimension is the spins, i.e. this will
range over all spins in the cluster.  The target function class is
initialised once per cluster (or per free spin), as defined by the
model_loop() API method.


</pre><blockquote class="blockquote"><pre style="margin: 0em;">Does i collect all the R2eff values for the clustered spins, and sent it to
the target function
together with the array of parameters to vary?
</pre></blockquote><pre style="margin: 0em;">

Yes, but again see the docstring for the fine details.  Looking at the
code for assembling the R2eff/R1rho data structures will also show
this.


</pre><blockquote class="blockquote"><pre style="margin: 0em;">Or does it calculate per spin, and share the common parameters?
</pre></blockquote><pre style="margin: 0em;">

The chi-squared is calculated per spin with the common parameters and
then summed over all spins of the cluster, all within one target
function call.  That will be the loop over si that you see inside each
target function.


</pre><blockquote class="blockquote"><pre style="margin: 0em;">My current bottle neck actually seems to be the saving of the state file,
between each iteration of global analysis.
</pre></blockquote><pre style="margin: 0em;">

You should have a look at what is being saved inside each file.  This
should only take a few seconds, or tens of seconds if you have Monte
Carlo simulations.  Which global analysis are you talking about?  Your
own custom analysis or the auto-analysis?  The auto-analysis saves
results files rather than state files (result files are simply one
data pipe whereas state files are everything in the data store,
including non-pipe structures).  If it is a custom analysis, then
maybe you are not resetting the relax data store between iterations
and hence your files will be becoming bigger and bigger with each
iteration - i.e. the number of data pipes is increasing each time.  Or
maybe you should use the results.write rather than state.save user
function.

Regards,

Edward


</pre>
<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
</div><!-- end msgdata -->
<br />
<h3><a name="related" href="#related">Related Messages</a></h3>
<div class="relateddata">
<!--X-Follow-Ups-End-->
<!--X-References-->
<ul><li><strong>References</strong>:
<ul>
<li><strong><a name="00004" href="msg00004.html">How is the R2eff data collected and processed for clustered analysis?</a></strong>
<ul><li><em>From:</em> Troels Emtekær Linnet</li></ul></li>
</ul></li></ul>
<!--X-References-End-->
<!--X-BotPNI-->
</div><!-- end relateddata -->
<!-- NoBotLinksApartFromRelatedMessages -->

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->
<div class="footer"></div><br />
<div class="right">Powered by <a href="http://www.mhonarc.org">MHonArc</a>, Updated Thu Jun 05 15:40:10 2014</div>  
</body>
</html>
